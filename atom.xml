<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Sun&#39;s Blog</title>
  
  <subtitle>Goose had left marks.</subtitle>
  <link href="https://www.virgilsun.com/atom.xml" rel="self"/>
  
  <link href="https://www.virgilsun.com/"/>
  <updated>2022-02-03T15:45:54.265Z</updated>
  <id>https://www.virgilsun.com/</id>
  
  <author>
    <name>Virgil Sun</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Notes on Merkle Tree from DSC 7th Ch23.6.6</title>
    <link href="https://www.virgilsun.com/Notes%20on%20Merkle%20Tree%20from%20DSC%207th%20Ch23.6.6/"/>
    <id>https://www.virgilsun.com/Notes%20on%20Merkle%20Tree%20from%20DSC%207th%20Ch23.6.6/</id>
    <published>2022-02-02T16:00:00.000Z</published>
    <updated>2022-02-03T15:45:54.265Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Merkle-tree-hash-tree"><a href="#Merkle-tree-hash-tree" class="headerlink" title="Merkle tree (hash tree)"></a>Merkle tree (hash tree)</h1><ul><li>Motivations<ul><li>effcient detection of inconsistent data stored at different replicas</li><li>sanity checks of replicas that are synchronously updated</li></ul></li><li>Data item structure<ul><li>each data item has a key and a value</li><li>if no explicit key: data item value can be used as a key</li></ul></li><li>Hash functions<ul><li>$h_1()$: hash each data item key $k_i$ to get a hash value with $n$ bits, where $2^n$ is within a small factor of the number of data items</li><li>$h_2()$: hash each data item value $v_i$ to get a hash value, typically longer than $n$ bits.</li><li>$h_3()$: inputs: a collection of hash values. outputs: a hash value (doesn’t depend on the input order, which can be done by sorting the collection before computing the hash)</li></ul></li><li>Merkle tree<ul><li>each node: associates with it an identifier, and stores a hash value<ul><li>identifier is $j$ bits long at depth $j$.</li></ul></li><li>each leaf<ul><li>identifier by an $n$-bit (at depth $n$) binary number.</li><li>hash collision: <ul><li>for a given leaf identified by number $k$, consider the set where $h_1(k_i)=k$.</li><li>then the hash value $v_k$ stored at leaf $k$ is computed by applying $h_2()$ on each $v_i$,</li><li>and then applying $h_3()$ on resultant collection of hash values.</li></ul></li></ul></li><li>The system also maintains an index that can retrieve all the data item with a given hash value computed by function $h_2()$.<ul><li>So MHT only stores hash value computed by $h_2()$ in leaves, hash=&gt;value mapping is maintained by other index in the system.</li></ul></li></ul></li><li>Example<ul><li><img src="https://s2.loli.net/2022/01/28/ISgsGlEurd839RD.png" alt="image.png"></li></ul></li><li>find difference between two replicas<ul><li>traverse down the node with different hash</li><li>cost: $O(m\log_2N)$, where $m$ is # different data items, $N$ is total number of data items (# leaf nodes is selected to be close to # data items).</li><li>Wider tree can reduce path length which would be $\log_KN$ if with $K$ children.</li></ul></li></ul>]]></content>
    
    
      
      
        
        
    <summary type="html">&lt;h1 id=&quot;Merkle-tree-hash-tree&quot;&gt;&lt;a href=&quot;#Merkle-tree-hash-tree&quot; class=&quot;headerlink&quot; title=&quot;Merkle tree (hash tree)&quot;&gt;&lt;/a&gt;Merkle tree (hash</summary>
        
      
    
    
    
    <category term="Database" scheme="https://www.virgilsun.com/categories/Database/"/>
    
    
    <category term="Merkle Tree" scheme="https://www.virgilsun.com/tags/Merkle-Tree/"/>
    
  </entry>
  
  <entry>
    <title>Notes on Secure Outsourced Aggregation via One-way Chains</title>
    <link href="https://www.virgilsun.com/Notes%20on%20Secure%20Outsourced%20Aggregation%20via%20One-way%20Chains/"/>
    <id>https://www.virgilsun.com/Notes%20on%20Secure%20Outsourced%20Aggregation%20via%20One-way%20Chains/</id>
    <published>2022-01-03T16:00:00.000Z</published>
    <updated>2022-01-05T13:24:37.666Z</updated>
    
    <content type="html"><![CDATA[<p>[TOC]</p><h1 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h1><ul><li><p>Scenario (unique characteristics): Wide-area shared sensing vs. typical wireless sensing aplication:</p><ul><li>Diverse queries</li><li>Push-based data collection: sensor push data to portal before queries are submitted</li></ul></li><li><p>Existing work (drawback): portal outsources such task to a third party, aggregator</p><ul><li>outsourced database: authenticate selection and join, not apply to aggregate</li><li>wireless sensor network: distributed aggregators secure, require communication with all sensors</li><li>proof-sketch: can work on push-based collection, but restricted to count-related aggregate, and not optimally-secure(both false positive &amp; negatives).</li></ul></li><li>Contributions<ul><li>SECOA, a framework with a family of novel optimally secure protocols</li><li>rich and diverse aggregate</li><li>don’t require sensors to be involved in each query, suitable for push-based collection</li></ul></li><li>Approach: one-way chain<ul><li>secure Max query</li><li>other aggregates (Count, Count Distinct, Sum, Average) can be readily reduced to Max</li><li>develope one-way-chain-based protocols for verifying a large set of aggregates (Uniform Samples, Quantiles, Top-k, etc.)</li><li>To reduce overhead, use one-way chain based on RSA encryption</li></ul></li></ul><h1 id="Related-Work"><a href="#Related-Work" class="headerlink" title="Related Work"></a>Related Work</h1><ul><li>Outsourced database<ul><li>many existing works ensure soundness and completeness</li><li>Scheme proposed by Li supports dynamical updates and ensures freshness</li><li>shortcoming:<ul><li>target aggregate: (range) selection queries on ordered data, join queries, set operation</li><li>query execution proofs can detect if an aggregator is lazy to compute aggregate function, but not prevent aggregator to report an incorrect result</li></ul></li></ul></li><li>Secure in-network aggregation<ul><li>SIA: single aggregator, not suitable for a large number of sensors</li><li>SHIA: supports multiple aggregators organized hierarchically (all sensors involved, pull-based), supports Count related queries.</li><li>Proof-sketch:<ul><li>can be modified in push-based, yet only supports count-related aggregate</li><li>complement predicates to verify, introduce both false positive &amp; negative.</li><li>Fundamentally: proof sketch can’t detect deflation(completeness), thus require complete predicates.</li></ul></li></ul></li></ul><h1 id="Preliminaries"><a href="#Preliminaries" class="headerlink" title="Preliminaries"></a>Preliminaries</h1><ul><li>Problem formulation<ul><li>architecture: trusted portal &lt;= malicious aggregator &lt;= malicious sensor</li><li>predicates: both portal &amp; aggregator have full list of sensors, s.t. can filter qualified sensor.<ul><li>:question: how about completeness of sensors? Is it the same as completeness for sensor’s reading?</li></ul></li><li>measures: sensor reading are restricted to positive integer…</li></ul></li><li>Security<ul><li>Let root aggregator include a list of failed sensors    。</li><li>Preventing aggregator include properly functioning sensor in failed list is orthogonal to this work, assume the liest is empty, if not just exclude those sensors.</li><li>:question: Excluding failed sensor is now tackled, what about filtering qualified sensor of predicates?</li></ul></li><li>One-way chain<ul><li>one-way function: easy to compute, computationally infeasible to revert (without knowing the trapdoor). Hash, or asymmetric encryption. They choose RSA encryption.</li><li>Notation: $F^x()$ denote recursively applying the function $F$ for $x$ times, called the SEAL (SElf-Authenticating vaLue) at position $x$. Can be <em>rolled forward</em>, i.e. compute SEAL at later position $y&gt;x$.</li></ul></li></ul><h1 id="Secure-Max-Aggregate"><a href="#Secure-Max-Aggregate" class="headerlink" title="Secure Max Aggregate"></a>Secure Max Aggregate</h1><p>With $K_i$ the symmetric key shared by portal and sensor $i$, $v_i$ the reading on sensor $i$ at the current recent epoch.</p><ul><li><p>Sensor $i$ reports to aggregator $\{v_i,s^+_i,F^{v_i}(s^-_i)\}$, where</p><ul><li>$s^+_i=\{i,\text{MAC}_{K_i}(v_i||epoch#)\}$</li><li>$s^-_i=\{\text{MAC}_{K_i}(epoch#)\}$</li></ul></li><li><p>Aggregator reports to portal $\{v_m, s^+_m, \odot_i F^{v_m}(s^-_i)\}$:</p><ul><li>prevent inflation (report a larger value):<ul><li>include $s^+_m$ where $m$ refers to the sensor with the max value. s.t. it can be verified that $v_m$ is indeed reported by some sensor.</li></ul></li><li>prevent deflation (report a smaller value)<ul><li><img src="https://s2.loli.net/2022/01/04/NhQocOvfZ1FMrXE.png" alt="image.png"></li><li>It can prevent aggregator to forge $F^2(s^-_2)$, since aggregator only knows $F^3(s^-_2)$ and can’t revert it one step ahead.</li><li>:white_check_mark:But can it prevent aggregator from not including the true max value?<ul><li>Portal computes each $s^-_i$, i.e. it has the list of all qualified sensors.</li></ul></li></ul></li></ul></li><li><p>portal verify $\sigma=\{v_m, s^+_m, f=\odot_i F^{v_m}(s^-_i)\}$:</p><ul><li><blockquote><p>computes all individual $s^-_i$’s and folds them together to create the RS of $\odot_i F^{v_m}(s^-_i)$</p></blockquote></li><li><p>:white_check_mark:How can portal compute all individual $s^-_i$?</p><ul><li>Because it’s just encrypted epoch number with different keys $s^-_i=\{\text{MAC}_{K_i}(epoch#)\}$.</li></ul></li></ul></li></ul><p><strong>Therefore, it doesn’t handle completeness, just soundness from 2 aspects (inflation, deflation)</strong>.</p><h1 id="Count-and-Related-Queries"><a href="#Count-and-Related-Queries" class="headerlink" title="Count and Related Queries"></a>Count and Related Queries</h1><h2 id="Basic-Protocols"><a href="#Basic-Protocols" class="headerlink" title="Basic Protocols"></a>Basic Protocols</h2><p><strong>Reduce Count to Max</strong></p><ul><li><p>AMS algorithm</p><ul><li>For each sensor $i$ whose reading satisfies predicates, pick a random positive integer $v_i$ with probability $2^{-v_i}$</li><li>Use max protocol to compute $v_m$, estimate the count as $2^{v_m}$.</li><li>Require pseudo-random number generator to verify sensor’s random number.</li><li>Proof<ul><li>pdf for random number generation: $f(x)=2^{-x}$. Note that $x\in \mathcal{Z}^+$, discrete.</li><li>TODO</li></ul></li></ul></li><li><p>Other approximating algorithms</p><ul><li><p>Let the random number generation ~ $U(0,1)$, estimate the count to be $1/(1-v_m)$.</p></li><li><p>Proof</p><ul><li><p>pdf of $X_i$: $f(x)=\frac{1}{b-a}=1$, cdf of $X_i$: $F(x)=\frac{x}{b-a}=x$</p></li><li><p>distribution of $Y=\max\{X_1,\ldots,X_n\}$:</p><script type="math/tex; mode=display">\begin{align}F_Y(y) &= Pr(\max\{X_1,\ldots,X_n\}\le y) = Pr(X_1\le y,\ldots,X_n\le y)\\&= Pr(X_1 \le y)\ldots Pr(X_n \le y) = F_X(y)^n = y^n\\f_Y(y) &= F_Y'(y)=ny^{n-1}\end{align}</script></li><li><p>Expectation of $Y$:</p><script type="math/tex; mode=display">\begin{align}E(Y) &= \int_0^1 y\cdot f_Y(y)dy = \int_0^1 ny^n dy = \frac{n}{n+1}\end{align}</script></li></ul></li></ul></li><li><p>FM sketch</p><ul><li>each sensor generate 1 bit at index $x$ with probability $2^x$ ( ~ Geometric distribution)</li><li>conduct bitwise OR on all bit vector, with the index of the lowest 0-bit to be $y$</li><li>Estimate count by $2^{y-1}/0.7735$.</li></ul></li></ul><p><strong>Aggregates related to Count</strong></p><ul><li>Distinct Count<ul><li>generate random number with sensor reading as seed</li></ul></li><li>Sum:<ul><li>with reading $v_i$, create $v_i$ sketches and merge them</li><li>Existing optimizations (including Li F’s ICDE)</li></ul></li><li>Mean:<ul><li>Sum / Count</li></ul></li><li>Count-Min<ul><li>be reduced to Count</li><li>can use to answer $k$-th statistical moments, median, quantiles, inner product queries, etc.</li></ul></li></ul><p><strong>High overhead of naive reduction</strong></p><p>Denote by $N$ the total # sensors.</p><ul><li><p>When generating RS, the portal needs to compute $s_i^-$ and roll it for $v_m$ times for each $i \in N$, and fold them together. That is, $N\cdot v_m$ roll operations, and $N$ fold operations.</p></li><li><p>To have reasonable estimation erroe, takle $J$ instances of AMS which usually needs to be large (e.g. a few hundreds).</p></li></ul><p>RSA is costly, but its homomorphic enables aggresive optimization. Introduce optimization next.</p><h2 id="Reducing-Rolling-Cost-via-Folded-Rolling"><a href="#Reducing-Rolling-Cost-via-Folded-Rolling" class="headerlink" title="Reducing Rolling Cost via Folded Rolling"></a>Reducing Rolling Cost via Folded Rolling</h2><p>A key source of overhead: roll a large number of SEALs individually, and fold resulted SEALs together. </p><ul><li><p>Folded rolling:</p><ul><li><p>idea: aggresively fold SEALs whenever possible, then roll the fold SEAL instead of individual SEALs.</p></li><li><p>To maximize benefits, roll the SEALs in the order of initial position (i.e. value). Thus total # rolling = $v_{\max}-v_{\min}$.</p><p><img src="https://s2.loli.net/2022/01/05/4R7bXtEDiMSJlaz.png" alt="image.png"></p></li><li><p>folded rolling relies on the homomorphic property of RSA, thus not applicable to MD5 or SHA-1, i.e. hash.</p></li></ul><h2 id="Reduce-Folding-Costs-via-B-Tree"><a href="#Reduce-Folding-Costs-via-B-Tree" class="headerlink" title="Reduce Folding Costs via B-Tree"></a>Reduce Folding Costs via B-Tree</h2></li></ul><h1 id="Top-k-Reading-and-Related-Queries"><a href="#Top-k-Reading-and-Related-Queries" class="headerlink" title="Top-k Reading and Related Queries"></a>Top-k Reading and Related Queries</h1><p>  Without loss of generality, assume sensor readings are all distinct (e.g. by appending sensor id)</p><h2 id="Protocol-Intuition"><a href="#Protocol-Intuition" class="headerlink" title="Protocol Intuition"></a>Protocol Intuition</h2><p>  Trivially answer a Top-k query by invoking Max query k times, each time exclude the max sensor $s_{i_1}$ last time (root aggregator needs to broadcast the final sensor to all aggregators) to get the second max sensor $s_{i_2}$. More precisely, the VS submitted to the portal in second round would be $(v_{i_2},s_{i_2}^+, \odot_{i\ne i_1}F^{v_{i_2}}(s_i^-))$.</p><p>  However, invoke Max sequentially may incur delay.</p><h2 id="Protocol-Description"><a href="#Protocol-Description" class="headerlink" title="Protocol Description"></a>Protocol Description</h2>]]></content>
    
    
      
      
        
        
    <summary type="html">&lt;p&gt;[TOC]&lt;/p&gt;
&lt;h1 id=&quot;Motivation&quot;&gt;&lt;a href=&quot;#Motivation&quot; class=&quot;headerlink&quot; title=&quot;Motivation&quot;&gt;&lt;/a&gt;Motivation&lt;/h1&gt;&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Scenario</summary>
        
      
    
    
    
    <category term="Database" scheme="https://www.virgilsun.com/categories/Database/"/>
    
    
    <category term="Aggregate" scheme="https://www.virgilsun.com/tags/Aggregate/"/>
    
    <category term="Outsourcing" scheme="https://www.virgilsun.com/tags/Outsourcing/"/>
    
  </entry>
  
  <entry>
    <title>Notes on Approximate Aggregation Techniques for Sensor Databases</title>
    <link href="https://www.virgilsun.com/Notes%20on%20Approximate%20Aggregation%20Techniques%20for%20Sensor%20Databases/"/>
    <id>https://www.virgilsun.com/Notes%20on%20Approximate%20Aggregation%20Techniques%20for%20Sensor%20Databases/</id>
    <published>2021-12-27T16:00:00.000Z</published>
    <updated>2021-12-28T13:06:22.388Z</updated>
    
    <content type="html"><![CDATA[<p>[TOC]</p><h1 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1 Introduction"></a>1 Introduction</h1><ul><li><p>Why data aggregation in sensor networks</p><ul><li>Many applications, like temperature reading, unnecessary to report entire data stream</li><li>Limited resource, frequent message is heavily consuming.</li></ul></li><li><p>How data aggregation in sensor networks (existing work)</p><ul><li>TAG system <a href="https://dl.acm.org/doi/pdf/10.1145/844128.844142" title="TAG: a Tiny AGgregation Service for Ad-Hoc Sensor Networks"><a href="https://dl.acm.org/doi/pdf/10.1145/844128.844142" title="TAG: a Tiny AGgregation Service for Ad-Hoc Sensor Networks">15</a></a> (spanning tree approach)<ul><li>Workflow:<ul><li>A base station connect to a sensor as the sink</li><li>Query is distributed over whole sensor network</li><li>Aggregate result sent back over a spanning tree, each node combine results from its children</li></ul></li><li><em>Cons</em>: don’t tolerate fault (node &amp; link):<ul><li>A single failure results in an entire subtree being lost</li><li>Retransmission can be expensive in this environment</li></ul></li></ul></li><li>Failure tolerant: multi-path routing<ul><li>Fault tolerant for monotonic and exemplary aggregates such as <em>MIN</em>, <em>MAX</em></li><li><em>Cons</em>: Incorrect for duplicate-sensitive aggregates such as <em>COUNT</em>, <em>AVG</em></li></ul></li></ul></li><li><p>Contributions</p><ul><li>Extend <em>duplicate insensitive sketches</em> to handle <em>SUM</em> aggregation with aggregation.</li><li>Combine sketches with multi-path routing for low communication and computation overhead.</li></ul></li><li>Concurrent work by Nath &amp; Gibbons <a href="https://dl.acm.org/doi/pdf/10.1145/1031495.1031525" title="Synopsis Diﬀusion for Robust Aggregation in Sensor Networks."><a href="https://dl.acm.org/doi/pdf/10.1145/1031495.1031525" title="Synopsis Diﬀusion for Robust Aggregation in Sensor Networks.">17</a></a>:<ul><li>logical decoupling of routing and aggregation</li><li>necessary sketch properties for correctness using multipath routing</li></ul></li></ul><h1 id="2-Background"><a href="#2-Background" class="headerlink" title="2 Background"></a>2 Background</h1><h2 id="2-1-Sensor-Devices"><a href="#2-1-Sensor-Devices" class="headerlink" title="2.1 Sensor Devices"></a>2.1 Sensor Devices</h2><ul><li>sensor environment<ul><li>limited resources: small battery power</li><li>bad communication: high packet loss rate</li></ul></li><li>Thus query evaluation methods different from traditional distributed query evaluation<ul><li>energy efficient</li><li>robust given communication limitations</li></ul></li></ul><h2 id="2-2-In-network-Aggregate-Query-Processing"><a href="#2-2-In-network-Aggregate-Query-Processing" class="headerlink" title="2.2 In-network Aggregate Query Processing"></a>2.2 In-network Aggregate Query Processing</h2><ul><li>Why in-network<ul><li>Naive solution: route all values to the base station, and compute the aggregate there<ul><li><em>Cons</em>: heavy communication and power consuming</li></ul></li><li>Better solution: leverage computational power of sensor devices and compute aggregates in-network</li></ul></li><li>Decomposibale functions<ul><li>Aggregates that can be computed in-network</li><li>definition: $f(v_1,v_2,\ldots,v_n)=g(f(v_1,\ldots,v_k),f(v_{k+1},\ldots,v_n))$ with merging function $g$.</li></ul></li><li>Wrokflow<ul><li>Two phases: <em>distribution</em> and <em>collection</em></li><li>Distribution:<ul><li>Flood the query in the network and organize nodes into an <em>aggregation tree</em>.</li><li>query message with a counter: hop distance from the root</li><li>each node chooses one of neighbors with a smaller hop to be its parent</li></ul></li><li>Collection<ul><li>Leaf node produces a single tuple, and forward this tuple to its parent</li><li>Non-leaf node receive and combine these values and submit to parent.</li><li>Energy saving: sleep, event/timer trigger</li></ul></li></ul></li><li>Approaches to address lossy network<ul><li>Cache previous values and reuse them if newer ones are unavailable</li><li>Fractional parents:<ul><li>Observation: a node may select multiple parents</li><li>Approach: decompose aggregate sum into fractions equal to #parents</li><li>example: sum=15, #parents=2, send each parent 7.5.</li><li>:question:Why? To enable correct solution under duplication? Doesn’t improve expected value, only reduce the variance. the problem of losing a signiﬁcant fraction of the aggregate value due to network failures remains.</li></ul></li></ul></li></ul><h2 id="2-4-Counting-Sketches"><a href="#2-4-Counting-Sketches" class="headerlink" title="2.4 Counting Sketches"></a>2.4 Counting Sketches</h2><p>Counting sketches were introduced by Flajolet and Martin <a href="http://algo.inria.fr/flajolet/Publications/src/FlMa85.pdf" title="Probabilistic Counting Algorithms for Data Base Applications"><a href="http://algo.inria.fr/flajolet/Publications/src/FlMa85.pdf" title="Probabilistic Counting Algorithms for Data Base Applications">7</a></a> (FM Sketch) for the purpose of quickly estimating the number of distinct items in a database (or stream) in one pass while using only a small amount of space.</p><ul><li>Space cost<ul><li>$\Omega(n)$ for exact solution</li><li>$\Theta(\log n)$ to approximate # distinct items in a multi-set with $n$ distinct items.</li></ul></li><li>Approaches<ul><li>FM sketch: achieve $\Theta(\log n)$ bound, with fixed hash function</li><li>linear hash function: larger, recent methods extend with only $O(\log\log n)$ space</li></ul></li></ul><h1 id="3-Sketch-Theory"><a href="#3-Sketch-Theory" class="headerlink" title="3 Sketch Theory"></a>3 Sketch Theory</h1><p>One of the core ideas behind our work is that duplicate insensitive sketches will allow us to leverage the robustness typically associated with multi-path routing.</p><h2 id="3-1-Counting-Sketches"><a href="#3-1-Counting-Sketches" class="headerlink" title="3.1 Counting Sketches"></a>3.1 Counting Sketches</h2><ul><li><p><em>Distinct counting problem</em></p><ul><li>Given a multi-set of items $M=\{x_1,x_2,\ldots\}$, compute $n\equiv |distinct(M)|$.</li></ul></li><li><p>FM sketch</p><ul><li>Given $M$, the FM sketch of $M$, denoted as $S(M)$, is a bitmap of length $k$.</li><li>Entries of $S(M)$, denoted $S(M)[0,\ldots,k-1]$, are initialilzed to zero</li><li>Entry is set to one using a random <em>binary</em> hash function $h$ applied to the elements of $M$.</li><li>Formally: $S(M)[i]\equiv 1 \text{iff} \exist x\in M  \text{s.t.} \min\{j|h(x,j)=1\}=i$.<ul><li>By this deﬁnition, each item $x$ is capable of setting a single bit in $S(M)$ to one – the minimum $i$ for which $h(x, i) = 1$.</li><li>Gives a simple serial implementation that’s fast in practice</li><li>Requires two invocations of $h$ per item on average</li></ul></li></ul></li><li><p>Theorem 1: An element $x_i$ can be inserted into an FM sketch in $O(1)$ expected time.</p><ul><li><p>～ Geometric distribution: $P(X=k)=(1-p)^{k-1}p$, $E[X]=\frac{1}{p}$. s.t. $E[X]=2$.</p></li><li><p>CountInsert algorithm</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">def CountInsert(S, x):</span><br><span class="line">i = 0;</span><br><span class="line">while hash(x,i) = 0 do</span><br><span class="line">i = i + 1;</span><br><span class="line">end while</span><br><span class="line">s[i] = 1;</span><br></pre></td></tr></table></figure></li></ul></li><li><p>Property 1: FM sketch of the union of two multi-sets is the bit-wise <em>OR</em> of their FM sketches</p><ul><li>$S(M_1 \cup M_2)[i]=(S(M_1)[i]\vee S(M_2)[i])$.</li><li>Node can compute a sketch of local data. Aggregation via union is cheap.</li></ul></li><li><p>Property 2: $S(M)$ is entirely determined by the distinct items of $M$. Duplication and ordering do not affect $S(M)$.</p><ul><li>Allow use of multi-path routing of the sketches for robustness without affecting the accuracy of estimates.</li></ul></li><li><p>Lemma 1:</p><ul><li>content<ul><li>For $i&lt;\log_2n-2\log_2\log_2n$, $S(M)[i]=1$ with probability $1-O(ne^{-\log_2^2n})$.</li><li>For $i\ge \frac{3}{2}\log_2n+\delta$, with $\delta\ge 0$, $S(M)[i]=0$ with probability $1-O(\frac{2^{-\delta}}{\sqrt{n}})$.</li></ul></li><li>provides key insight into the behavior of FM sketches and will be the basis of eﬃcient implementations of summation sketches. lemma is proven in <a href="http://algo.inria.fr/flajolet/Publications/src/FlMa85.pdf" title="Probabilistic Counting Algorithms for Data Base Applications"><a href="http://algo.inria.fr/flajolet/Publications/src/FlMa85.pdf" title="Probabilistic Counting Algorithms for Data Base Applications">7</a></a> and follows from basic balls and bins arguments.</li><li>one expects an initial preﬁx of all ones and a suﬃx of all zeros, while only the setting of the bits around $S(M)[log_2n]$ exhibit much variation.</li><li>This gives a bound on the number of bits $k$ required for $S(M)$ in general: $k = \frac{3}{2}\log_2n$ bits suﬃce to represent $S(M)$ with high probability.</li></ul></li><li><p>Define $R_n\equiv \min\{i|S(M)[i]=0\}$, i.e. a random variable marking the first zero in $S(M)$.</p></li><li>Theorem 2: Expectation of $R_n$<ul><li>$E[R_n]=\log_2(\varphi n)+P(\log_2n)+o(1)$</li><li>where constant $\varphi$ is approximately $0.775351$</li><li>and $P(u)$ is a periodic and continuous function of $u$ with period $1$ and cmplitude bounded by $10^{-5}$.</li></ul></li><li>Theorem 3: Variance of $R_n$<ul><li>$\sigma_n^2=\sigma_\infty^2+Q(\log_2n) + o(1)$</li><li>where $\sigma_\infty^2$ is approximately $1.12127$</li><li>and $Q(u)$ is a periodic function with mean $0$ and period $1$.</li></ul></li><li>Estimate $n$<ul><li>$R_n$ can be used for an unbiased estimator of $\log_2n$ is the small periodic term $P(\log_2n)$ is ignored.</li><li>However, the variance $\sigma_n^2$ is slightly more than one, thusthe estimates of $n$ will often be off by a factor of two or more in either direction. Methods to reduce variance will be discussed in Section 3.3.</li></ul></li></ul><h2 id="3-2-Summation-Sketches"><a href="#3-2-Summation-Sketches" class="headerlink" title="3.2 Summation Sketches"></a>3.2 Summation Sketches</h2><p>As our ﬁrst theoretical contribution, we generalize approximate counting sketches to handle summations.</p><ul><li><p><em>Distinct summation problem</em></p><ul><li>Give a multi-set $M=\{x_1,x_2,\ldots \}$ where $x_i=(k_i,c_i)$ and $c_i$ is a non-negative integer</li><li>Distinct summation problem: calculate $n \equiv \sum_{\text{distinct}((k_i,c_i)\in M)}c_i$.</li><li>When $c_i$ is restricted to one, it’s exactly the distinct counting problem.</li></ul></li><li><p>Summation insertion</p><ul><li><p>For small values of $c_i$, may treat one summation insertion as $c_i$ counting insertions, e.g. $(k_i, c_i,1),\ldots,(k_i,c_i,c_i)$, denoted <em>subitems</em> of $(k_i, c_i)$ . Thus expected insertion time: $O(c_i)$. doesn’t scale for large value.</p></li><li><p>More scalable solutions:</p><ul><li><pre><code class="lang-pseudocode">def SumInsertion(S, x, c):    d = pick_threshold(x);    for i = 0, ..., d - 1 do        S[i] = 1;    end for    a = pick_binomial(seed=(x, c), c, 1/2^d);    for i = 1, ..., a do        j = d;        while hash(x, c, i, j) = 0 do            j = j + 1;        end while        S[j] = 1;    end for</code></pre></li><li><p>First step: set prefix to one</p><ul><li>Follow from Lemma 1, the first $\delta_i=\lfloor \log_2c_i - 2\log_2\log ci \rfloor$ bits of a counting sketch have high probability to be one.</li><li>So the first step to insert $(k_i, c_i)$  into the summation sketch is to set first $\delta_i$ bits to one.</li><li>As proved in <a href="http://algo.inria.fr/flajolet/Publications/src/FlMa85.pdf" title="Probabilistic Counting Algorithms for Data Base Applications"><a href="http://algo.inria.fr/flajolet/Publications/src/FlMa85.pdf" title="Probabilistic Counting Algorithms for Data Base Applications">7</a></a>, the case where first $\delta_i$ bits are not all set to one only affects $E[R_n]$ by $O(n^{-0.49})$.</li></ul></li><li><p>Second step: set remaining $k-\delta_i$ bits</p><ul><li>Simulating insertions in counting sketch. Define an insertion $x_i$ <em>reaches</em> bit $z$ of a counting sketch iff $\min\{j | h(x_i, j)=1\}\ge z$.<ul><li>iff $\forall_{0\le j&lt;z}(h(x_i,j)=0)$, which occurs with probability $2^{-z}$.</li><li>Thus, for $c_i$ insertions, # insertions reaching bit $\delta_i$  ~ $B(c_i,2^{-\delta_i})$.</li></ul></li><li>Workflow:<ul><li>Draw a random sampling $a$ ~ $B(c_i, 2^{-\delta_i})$, consider as $a$ insertions reach bit $\delta_i$.</li><li>For each insertion $i \in a$,  use FM coin-flipping to set its cooreponding bit after $\delta_i$ to be one.</li></ul></li></ul></li></ul></li></ul></li><li><p>Theorem 4 (Sum Insertion time): expected time for a single insertion of element $x_i=(k_i,c_i)$ in sum sketch is $O(\log^2c_i)$.</p><ul><li><p>Proof Sketch:</p><ul><li><p>Total expecte time: $O(\delta_i + f(\alpha_i) + \alpha_i)$. Thus time depends on both $\alpha_i$ and method to selelct $\alpha_i$.</p><ul><li>Setting first $\delta_i$ bits takes $O(\delta_i)$ time</li><li>Denote # items sampled to reach $\delta_i$ as $\alpha_i$. Simulating all $\alpha_i$ insertions take expected $O(\alpha_i)$ time. (Expected $O(2)$ for each insertion  $\in \alpha_i$).</li><li>$f(\alpha_i)$ denotes the time to sample $\alpha_i$.</li></ul></li><li><script type="math/tex; mode=display">\begin{align}E[\alpha_i] &= c_i*2^{-\delta_i}\\&= c_i*2^{-\lfloor \log_2c_i - 2\log_2\log c_i \rfloor} \\\therefore \log^2c_i \le E[\alpha_i] &< 2\log^2c_i\end{align}</script></li></ul></li><li><p>Appropriate method to pick $\alpha_i$.</p><ul><li>Existing method for generating numbers ~ Binomial() require floating point operation or considerable memory for pre-computed table. Not suitable for resource-limited sensors.</li><li>Propose a space-efficient method using no floating point, and pre-computed table of size $O(c/\log^2 c)$ in sec 4.3.1.</li></ul></li></ul></li><li><p>Theorem 5: Expected value of $R_n$.</p><ul><li>$E[R_n]=\log_2(\varphi n) + P(\log_2 n)+o(1)$</li></ul></li><li>Theorem 6: Variance of $R_n$.<ul><li>$\sigma_n^2=\sigma_\infty^2+Q(\log_2n)+o(1)$</li></ul></li></ul><h2 id="3-3-Improving-Accuracy"><a href="#3-3-Improving-Accuracy" class="headerlink" title="3.3 Improving Accuracy"></a>3.3 Improving Accuracy</h2><p>To improve accuracy and confidence (reduce varaince), use multiple bitmap like Bloom filter.</p><ul><li>Naive solution on multiple bitmap:<ul><li>workflow: insert into each of $m$ independent bitmaps to produce $m$ $R_n$ values: $R^{\langle 1 \rangle},\ldots,R^{\langle m \rangle}$.</li><li>estimation: $n \approx \frac{1}{\varphi}2^{\sum_i R^{\langle i \rangle}/m}$.</li><li>lower variance: $O(\frac{1}{\sqrt{m}})$</li><li>but higher insertion cost: $O(m)$.</li></ul></li><li>An improved approach: <em>Probabilistic Counting with Stochastic Averaging</em> (PCSA)<ul><li>Idea: Don’t insert to each bitmap, but as hash bucket only insert to 1 of m bitmaps.</li><li>variance: $0.78/\sqrt{m}$. expected insertion time: $O(1)$.</li><li>Extend to sum sketch requires tackling imbalancing: since a single item can contribute an arbitrarily large fraction of the total sum, i.e. large $c_i$.<ul><li>take the form: $c_i=q_im+r_i$<ul><li>add $r_i$ distinct items once as in standard PCSA</li><li>add $q_i$ to each bitmap independently.</li></ul></li><li>higher insertion cost: $O(m\log^2(c_i/m))$.</li></ul></li></ul></li></ul><h2 id="3-4-Tradeoffs-and-Other-Approaches"><a href="#3-4-Tradeoffs-and-Other-Approaches" class="headerlink" title="3.4 Tradeoffs and Other Approaches"></a>3.4 Tradeoffs and Other Approaches</h2><p>TODO</p><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1>]]></content>
    
    
      
      
        
        
    <summary type="html">&lt;p&gt;[TOC]&lt;/p&gt;
&lt;h1 id=&quot;1-Introduction&quot;&gt;&lt;a href=&quot;#1-Introduction&quot; class=&quot;headerlink&quot; title=&quot;1 Introduction&quot;&gt;&lt;/a&gt;1</summary>
        
      
    
    
    
    <category term="Database" scheme="https://www.virgilsun.com/categories/Database/"/>
    
    
    <category term="Aggregate" scheme="https://www.virgilsun.com/tags/Aggregate/"/>
    
  </entry>
  
  <entry>
    <title>Notes on Blockchains vs. Distributed Databases Dichotomy and Fusion</title>
    <link href="https://www.virgilsun.com/Notes%20on%20Blockchains%20vs.%20Distributed%20Databases%20Dichotomy%20and%20Fusion/"/>
    <id>https://www.virgilsun.com/Notes%20on%20Blockchains%20vs.%20Distributed%20Databases%20Dichotomy%20and%20Fusion/</id>
    <published>2021-12-19T16:00:00.000Z</published>
    <updated>2021-12-28T13:17:05.873Z</updated>
    
    <content type="html"><![CDATA[<p>[TOC]</p><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><ul><li>Propose a taxonomy with 4 dimensions:<ul><li>replication</li><li>concurrency</li><li>storage</li><li>sharding</li></ul></li></ul><h2 id="Background"><a href="#Background" class="headerlink" title="Background"></a>Background</h2><h3 id="Distributed-Databases"><a href="#Distributed-Databases" class="headerlink" title="Distributed Databases"></a>Distributed Databases</h3><ul><li>NoSQL vs. NewSQL<ul><li>NoSQL:<ul><li>flexible data structure: kv, document, graph, column</li><li>weaker consistency: eventual, sequential, causal, PRAM</li></ul></li><li>NewSQL:<ul><li>Spanner, CockroachDB, TiDB</li></ul></li></ul></li></ul><h2 id="Taxonomy"><a href="#Taxonomy" class="headerlink" title="Taxonomy"></a>Taxonomy</h2><h3 id="Replication"><a href="#Replication" class="headerlink" title="Replication"></a>Replication</h3><h4 id="Replication-model"><a href="#Replication-model" class="headerlink" title="Replication model."></a>Replication model.</h4><ul><li><p>Unit of replication</p><ul><li><p>ordered log of transactions(ledger): Blockchain</p><ul><li>replicate entire transaction, contain applicatiom-level information, easy to perform veirfication</li></ul></li><li><p>ordered log of read and write operations on top of storage: Distributed database</p><ul><li>see only one operation at a time, transaction manager need to be trusted, and more concurrency since operations can be replicated in different order but with the same effect on the storage.</li></ul></li></ul></li></ul><h4 id="Replication-approach"><a href="#Replication-approach" class="headerlink" title="Replication approach."></a>Replication approach.</h4><ul><li>Primary-backup:<ul><li>dedicate a replica as the primary which synchronizes its states with backup replicas</li></ul></li><li>State-machine replication<ul><li>maintain an ordered log of operations/transactions on each replica which starts at the same initial state and applies the operations/transactions in the same order in the log.</li><li>methods<ul><li>consensus protocol<ul><li>all replicas agree on the ordered log</li><li>compared with primary-backup: automatic primary failover by view change (elect a new primary)</li></ul></li><li>shared log:question:: rely on external services that provide a distributed shared log abstraction<ul><li>Operations/transactions are appended to the log, and the replicas, as clients of the log, apply them independently.</li><li>Shared log decouples ordering from state replication, thus high throughput remain constant until # log consumers exceeds the capacity of the log producer.</li></ul></li></ul></li></ul></li></ul><h4 id="Failure-model"><a href="#Failure-model" class="headerlink" title="Failure model."></a>Failure model.</h4><ul><li>node failure<ul><li>CFT</li><li>BFT</li></ul></li><li>network assumption<ul><li>synchronous: bounded and known delay</li><li>asynchronous: unbounded</li></ul></li></ul><h3 id="Concurrency"><a href="#Concurrency" class="headerlink" title="Concurrency"></a>Concurrency</h3><ul><li>concurrency: the extent to which transactions are executed at the same time.<ul><li>serially (sequentially)</li><li>concurrently</li></ul></li><li><p>two reason for BC’s lack of concurrency</p><ul><li>First, serial execution may not affect the overall performance because transaction execution is often not the bottleneck.</li><li>Second, serial execution means the behavior of smart contracts is deterministic when the transaction execution is replicated over many nodes.</li></ul></li><li><p>challenge in extracting concurrency: ensure corretness of concurrent execution</p><ul><li>isolation level: tradeoff between correctness nad performance</li></ul></li><li><p>blockchain adopt concurrency techniques</p><ul><li>Hyperledger:<ul><li>txns are simulated (executed) in parallel before ordering</li><li>achieve serializability with simple optimistic concurrency control that aborts txns wieh stale simulated states.</li></ul></li><li>Reduce abort: txn on EOV (SIGMOD2020), Blurring the lines (SIGMOD2019)</li></ul></li></ul><h3 id="Storage"><a href="#Storage" class="headerlink" title="Storage"></a>Storage</h3><h4 id="Storage-model"><a href="#Storage-model" class="headerlink" title="Storage model."></a>Storage model.</h4><ul><li>storage<ul><li>built upon latest states only, amenable for mutation</li><li>built upon all historical information, amenable for appending</li></ul></li><li>DB without provenance: historical data is maintained limited, e.g. write-ahead logs (WAL).<ul><li>WAL: used primarily for failure recovery, periodically pruned.</li></ul></li></ul><h4 id="Index"><a href="#Index" class="headerlink" title="Index."></a>Index.</h4><ul><li>index role<ul><li>data access performance: distributed system<ul><li>hardware-conscious: e.g. in-memory db abandon disk-friendly B-tree for FAST and PSL designed for better cache utilization and multi-core parallelism.</li></ul></li><li>security-oriented system use index to compute a digest to uniquely identifies the state contents. (ADS) : blockchain<ul><li>MHT, MPT, MBT</li></ul></li></ul></li></ul><h3 id="Sharding"><a href="#Sharding" class="headerlink" title="Sharding"></a>Sharding</h3><ul><li>challenges<ul><li>how to form a shard</li><li>how to ensure atomicity for cross-shard transactions</li></ul></li></ul><h4 id="Shard-formation"><a href="#Shard-formation" class="headerlink" title="Shard formation."></a>Shard formation.</h4><p>A shard formation protocol determines which nodes and data go to which shard.</p><ul><li><p>shard formation protocol in blockchain</p><ul><li><p>requirements:</p><ul><li>shard size large enough s.t. fraction of Byzantine nodes doesn’t surpass the BFT threshold</li><li>attacker can’t influence shard assignment</li></ul></li><li><p>example:</p><ul><li>Elastico: PoW; Ethereum: PoS; Omniledger: complex cryptographic protocol; AHL: trusted hardware</li></ul></li></ul></li><li><p>in ditributed database</p><ul><li>goal of sharding: scalability</li><li>To optimize performance of certain workloads, different partitioning scheme: hash/range partitioning</li><li>Example: Cassandra allow user-specified workload distribution s.t. partition data in a locality-aware manner.</li></ul></li></ul><h4 id="Atomicity"><a href="#Atomicity" class="headerlink" title="Atomicity."></a>Atomicity.</h4><p>Atomicity requires a cross-shard transaction to either commit or abort in all shards.</p><ul><li>distributed DB:<ul><li>2PC protocol, require trusted transaction coordinator</li></ul></li><li>Blockchain: coordinator can’t be trusted<ul><li>Eth2: to overcome it, introduce a separate chain (Beacon Chain) running Casper consensus to coordinate cross-shard transactions.</li><li>implement the 2PC coordinator as a state machine in a shard that runs a BFT protocol. [41][51]</li></ul></li></ul><h3 id="Fusion-of-Blockchains-and-Databases"><a href="#Fusion-of-Blockchains-and-Databases" class="headerlink" title="Fusion of Blockchains and Databases"></a>Fusion of Blockchains and Databases</h3><h4 id="Out-of-the-blockchain-Databases"><a href="#Out-of-the-blockchain-Databases" class="headerlink" title="Out-of-the-blockchain Databases"></a>Out-of-the-blockchain Databases</h4><p>Build database feature on top of the blockchain: BlockchainDB, Veritas, FalconDB</p><h4 id="Out-of-the-database-Blockchains"><a href="#Out-of-the-database-Blockchains" class="headerlink" title="Out-of-the-database Blockchains"></a>Out-of-the-database Blockchains</h4><p>Start with a database, then add blockchain features to it.</p><p>Each node has its own database and executes transactions on its database according to a global order achieved through consensus.</p><h3 id="Discussion"><a href="#Discussion" class="headerlink" title="Discussion"></a>Discussion</h3><p><img src="https://s2.loli.net/2021/12/20/3Dse1RACpVrSNyt.png" alt="image.png"></p><h2 id="Experiment"><a href="#Experiment" class="headerlink" title="Experiment"></a>Experiment</h2><p>TODO</p>]]></content>
    
    
      
      
        
        
    <summary type="html">&lt;p&gt;[TOC]&lt;/p&gt;
&lt;h2 id=&quot;Introduction&quot;&gt;&lt;a href=&quot;#Introduction&quot; class=&quot;headerlink&quot; title=&quot;Introduction&quot;&gt;&lt;/a&gt;Introduction&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;Propose a</summary>
        
      
    
    
    
    <category term="Blockchain" scheme="https://www.virgilsun.com/categories/Blockchain/"/>
    
    
    <category term="Blockchain" scheme="https://www.virgilsun.com/tags/Blockchain/"/>
    
    <category term="Distributed Database" scheme="https://www.virgilsun.com/tags/Distributed-Database/"/>
    
  </entry>
  
  <entry>
    <title>Notes on BlockSci</title>
    <link href="https://www.virgilsun.com/Notes%20on%20BlockSci/"/>
    <id>https://www.virgilsun.com/Notes%20on%20BlockSci/</id>
    <published>2021-12-09T16:00:00.000Z</published>
    <updated>2021-12-10T14:13:00.028Z</updated>
    
    <content type="html"><![CDATA[<h2 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1 Introduction"></a>1 Introduction</h2><ul><li>3 pain points of existing tools:<ul><li>Poor performance</li><li>Limited capabilities</li><li>Cumbersome programming interface</li></ul></li><li>To overcome those drawbacks<ul><li>Compared to <em>general-purpose graph db</em>, BlockSci is hundreds of time faster for <em>sequential queries</em>, and substantially faster for all queries, including <em>graph traversal queries</em></li><li>Bundled with analytical modules such as address clustering, exposes different blockchains, collects mempool state, etc.</li><li>Multiple programming interface</li></ul></li><li>design<ul><li>In-memory analytical db</li><li>Tricks to increase speed and decrease data size: convert hash pointers to actual pointers, deduplicate address data</li><li>Scale vertically, memory large enough</li><li>Avoiding distributed processing: since blockchain data is graph structured, thus hard to partition effectively.</li></ul></li><li>Battery included:<ul><li>multi-chain mode</li><li>library of useful analytic tools</li><li>record tx time and expose them through the same interface</li></ul></li></ul><h2 id="2-Design-and-architecture"><a href="#2-Design-and-architecture" class="headerlink" title="2 Design and architecture"></a>2 Design and architecture</h2><ul><li>overview</li></ul><p><img src="https://s2.loli.net/2021/12/09/RkfIsLZeBihj52H.png" alt="image.png"></p><h3 id="2-1-Recording-and-importing-data"><a href="#2-1-Recording-and-importing-data" class="headerlink" title="2.1 Recording and importing data"></a>2.1 Recording and importing data</h3><ul><li>Supported blockchains:<ul><li>Support UTXO based blockchains</li><li>Multi-chain mode: forked chains can be combined in a memory-efficient multichain configuration<ul><li>common data is loaded only once</li><li>address data is deduplicated across forks, enable cross-chain analysis</li></ul></li></ul></li><li>Importer<ul><li>Json RPC: small chain</li><li>on-disk raw data: larger chain</li></ul></li><li>Mempool recorder<ul><li>The waiting time of included transactions provides valuable data for economic analyses and isn’t recorded in the blockchain itself.</li></ul></li></ul><h3 id="2-2-Parser"><a href="#2-2-Parser" class="headerlink" title="2.2 Parser"></a>2.2 Parser</h3><ul><li>Parsing is sequential and stateful<ul><li>2 types of states are required for transformation:<ul><li>link a tx’s input to a prior tx’s output (represented as <tx hash, output index>)</li><li>link input/output to addresses: assign ID to every tx and address, maintain UTXO set and hash ID mapping.</li></ul></li><li>Intra-block tx order<ul><li>BTC: chronological order</li><li>BCH: canonical transaction ordering (CTOR), i.e., based on hash.</li><li>Thus multiple pass for parser to link tx, toleranting arbitrary ordering of tx.</li></ul></li><li>Deletion<ul><li>UTXO can be deleted from the parser state after spending</li><li>Address mapping can’t be discarded, since any address can be used by outputs. <em>Must be tracked all time.</em></li></ul></li></ul></li><li><p>Optimization (address storage): Bloom filters and address caches</p><ul><li>Two oberservations:<ul><li>Vast majority of inputs spend recently created outputs: $88\%$ inputs spend outpus created in last $4000$ blocks.</li><li>Only $8.6\%$ BTC addresses are used more than once, but account for $51\%$ of all occurrences.</li></ul></li><li>Optimizations:<ul><li>A Bloom filter stores all seen addresses: ensures correctness of existing addresses, while minimizing queries on nonexistent ones.</li><li>A multi-use address cache: contains addresses that have been used multiple times.</li><li>Address hashes are stored in RocksDB to flush in disk.</li></ul></li></ul></li><li><p>Shared state across chains</p><ul><li>shares and reuse parser states, such as bloom filter of seen addresses, shared a single db s.t. address data is deduplicated.</li></ul></li><li>Incremental updates<ul><li>Append-only nature of blockchain</li><li>The parser serializes its ﬁnal state at the end of a run, and resumes from that state when invoked again.</li><li>Handle reorganization from forks: ignore the most recent few blocks during initialization.</li></ul></li></ul><h3 id="2-3-BlockSci-Data"><a href="#2-3-BlockSci-Data" class="headerlink" title="2.3 BlockSci Data"></a>2.3 BlockSci Data</h3><ul><li><p>3 categories of datas</p><ul><li>The core tx graph: always in-memory, stored in row-based format</li><li>Scripts and additional data: hybrid (partially column-based, partially row-based)</li><li>Indices to look up tx or addresses by Hash: on-disk db.</li></ul></li><li><p>Tx graph.</p><ul><li><p>stored in a single sequential table of tx with following entry structure:</p><p><img src="https://s2.loli.net/2021/12/09/B67UL1PgEc2Otjb.png" alt="image.png"></p></li><li><p>variable length record:</p><ul><li>due to variable # inputs/outputs</li><li>normal impementation: heap organization, which is memory consuming and worse locality of reference.</li><li>special append-only property, only 2 kinds of modifications:<ul><li>appending new entries (due to new tx)</li><li>length-preserving edits to existing entries (when existing utxo is consumed).</li></ul></li><li>Final implementation:<ul><li>flat file on disk, grow linearly.</li><li>To load the file for analysis, map into memory.</li><li>The on-disk data can keep growing (and modified in place), while in-memory data provides a static view.</li></ul></li></ul></li><li><p>Layout and locality</p><ul><li>Sequential analysis exhibits strong locality, enable sequential I/O instead of random I/O.</li><li>Store both input and output in tx:<ul><li>con: slightly duplication (a space cost of about $19\%$)</li><li>pros: significant speedup for sequential iteration compared to a normalized layout.</li></ul></li></ul></li></ul></li><li><p>Indices</p><ul><li>ID to Hash: tx/addr hash are stored in flat files, with ID as key.</li><li>Hash to ID: stored in separate indices in RocksDB</li></ul></li></ul><h3 id="2-4-BlockSci-Analysis-Library"><a href="#2-4-BlockSci-Analysis-Library" class="headerlink" title="2.4 BlockSci Analysis Library"></a>2.4 BlockSci Analysis Library</h3><ul><li>Snapshot illusion<ul><li>The blockchain on disk increases over time, but the stored height remains ﬁxed, and accesses to blocks past this height are prevented.</li></ul></li><li>Memory mapping and parallelism<ul><li>BlockSci uses the same format for tx graph both in memory and on disk, thus loading only involves mapping.</li><li>Multithread:<ul><li>When a file is mapped into memory by multiple processes, they use the same physical memory.</li><li>Only one writer (the parser), analysis library won’t overwrite.</li></ul></li></ul></li><li>Mapreduce<ul><li>The analysis library supports mapreduce abstraction, handles parallelizing the task to utilize all available cores.</li></ul></li><li>Address linking.<ul><li>Two common types of heuristics<ol><li>inputs spent in the same transaction are controlled by the same entity</li><li>identifying a change address based on client software or user behavior</li></ol></li><li>These heuristics create links (edges) in a graph of addresses, generate clusters of addresses as output.</li></ul></li></ul><h3 id="2-6-Performance-Evaluation"><a href="#2-6-Performance-Evaluation" class="headerlink" title="2.6 Performance Evaluation"></a>2.6 Performance Evaluation</h3><h4 id="2-6-1-Basic-run-time-statistics"><a href="#2-6-1-Basic-run-time-statistics" class="headerlink" title="2.6.1 Basic run time statistics"></a>2.6.1 Basic run time statistics</h4><ul><li>Query:<ul><li>Mapreduce-style iteration over the blockchain</li><li>Example: ﬁnding transactions with anomalously high fees. Require traversing not onlt tx, but also input and output.</li></ul></li><li>Result<ul><li><img src="https://s2.loli.net/2021/12/10/AIET5bpmaCjzwVW.png" alt="image.png"></li></ul></li></ul><h4 id="2-6-2-Comparison-with-graph-database"><a href="#2-6-2-Comparison-with-graph-database" class="headerlink" title="2.6.2 Comparison with graph database"></a>2.6.2 Comparison with graph database</h4><ul><li><p>Compared graph database:</p><ul><li><p>Neo4j, RedisGraph, Memgraph</p></li><li><p>graph property model: model blocks, transactions, outputs, and addresses as nodes</p><p><img src="https://s2.loli.net/2021/12/10/KpZJafdF5ghNkIs.png" alt="image.png"></p></li></ul></li><li><p>Query</p><ul><li>Iterative queries<ul><li>ﬁnding transactions with a positive locktime</li><li>ﬁnding the highest output value</li><li>ﬁnding the highest transaction fee</li></ul></li><li>Graph traversal<ul><li>calculating the total value received by a popular address</li><li>counting the number of outputs that have been spent in the same block</li><li>identifying transactions where exactly one output has been spent in a transaction that uses a similar locktime policy</li></ul></li></ul></li><li><p>Result</p><ul><li><img src="https://s2.loli.net/2021/12/10/6fusewCKcdOrlxT.png" alt="image.png"></li><li></li></ul></li></ul>]]></content>
    
    
      
      
        
        
    <summary type="html">&lt;h2 id=&quot;1-Introduction&quot;&gt;&lt;a href=&quot;#1-Introduction&quot; class=&quot;headerlink&quot; title=&quot;1 Introduction&quot;&gt;&lt;/a&gt;1 Introduction&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;3 pain points</summary>
        
      
    
    
    
    <category term="Blockchain" scheme="https://www.virgilsun.com/categories/Blockchain/"/>
    
    
    <category term="OLAP" scheme="https://www.virgilsun.com/tags/OLAP/"/>
    
  </entry>
  
  <entry>
    <title>Notes on Database System Concepts - Ch24 Advanced Indexing</title>
    <link href="https://www.virgilsun.com/Notes%20on%20Database%20System%20Concepts%20-%20Ch24%20Advanced%20Indexing/"/>
    <id>https://www.virgilsun.com/Notes%20on%20Database%20System%20Concepts%20-%20Ch24%20Advanced%20Indexing/</id>
    <published>2021-12-08T16:00:00.000Z</published>
    <updated>2021-12-09T04:37:59.000Z</updated>
    
    <content type="html"><![CDATA[<p>[TOC]</p><h1 id="Ch24-Advanced-Indexing-Techniques"><a href="#Ch24-Advanced-Indexing-Techniques" class="headerlink" title="Ch24 Advanced Indexing Techniques"></a>Ch24 Advanced Indexing Techniques</h1><h2 id="24-1-Bloom-Filter"><a href="#24-1-Bloom-Filter" class="headerlink" title="24.1 Bloom Filter"></a>24.1 Bloom Filter</h2><p><strong>Bloom filter</strong>: Check for membership of a value in a set. If the set has $n$ values, the associated bitmap has a few times $n$ (typically $10n$) bits. The bloom filter associates with several hash functiosn to determine the position of an element in the bitmap.</p><p>All initially set to 0, for each value in the set, set the bit at position $h(v)$ to be 1.</p><p>To check whether a value $v$ is in the set, check the bit ast $h(v)$, but with probability for false positive.</p><p>To reduce the chance of false positives, use $k$ independent hash functions. If value $v$ in the set, then all $k$ positions at $h_i(v)$ should be 1.</p><h2 id="24-2-Log-Structured-Merge-Tree-and-Variants"><a href="#24-2-Log-Structured-Merge-Tree-and-Variants" class="headerlink" title="24.2 Log-Structured Merge Tree and Variants"></a>24.2 Log-Structured Merge Tree and Variants</h2><p>The key idea of the log-structured merge tree (LSM tree) is to replace random I/O operations during tree inserts, updates, and deletes with a smaller number of sequential I/O operations.</p><h3 id="24-2-1-Insertion-into-LSM-Trees"><a href="#24-2-1-Insertion-into-LSM-Trees" class="headerlink" title="24.2.1 Insertion into LSM Trees"></a>24.2.1 Insertion into LSM Trees</h3><p># levels</p><h3 id="24-2-2-Rolling-Merges"><a href="#24-2-2-Rolling-Merges" class="headerlink" title="24.2.2 Rolling Merges"></a>24.2.2 Rolling Merges</h3><p>Heavy I/O load during merge, but no I/O for unmerge. Do merging on a continuous basis: a few pages of $L_i$ are merged into corresponding pages of $L_i$ at a time, and removed from $L_i$.</p><h3 id="24-2-3-Handling-Deletes-and-Updates"><a href="#24-2-3-Handling-Deletes-and-Updates" class="headerlink" title="24.2.3 Handling Deletes and Updates"></a>24.2.3 Handling Deletes and Updates</h3><p>delete entry</p><h3 id="24-2-4-The-Stepped-Merge-Index"><a href="#24-2-4-The-Stepped-Merge-Index" class="headerlink" title="24.2.4 The Stepped-Merge Index"></a>24.2.4 The Stepped-Merge Index</h3><p>Multiple trees at each level.</p><h4 id="24-2-4-1-Insertion-Algorithm"><a href="#24-2-4-1-Insertion-Algorithm" class="headerlink" title="24.2.4.1 Insertion Algorithm"></a>24.2.4.1 Insertion Algorithm</h4><p>To limit the overhead on lookups (# trees at $L_1$ is unlimited), we limit # trees at each level to be $k$, beyond which those trees are merged to the next level.</p><h4 id="24-2-4-2-Lookup-Operations-Using-Bloom-Filters"><a href="#24-2-4-2-Lookup-Operations-Using-Bloom-Filters" class="headerlink" title="24.2.4.2 Lookup Operations Using Bloom Filters"></a>24.2.4.2 Lookup Operations Using Bloom Filters</h4><p>More read overheads, since worst case need to access $k$ trees at each level.</p><p>To reduce the cost of point lookup, most systems use a Bloom filter to check if a tree can possibly contain the given key value.</p><p>Note that for range lookups, the Bloom ﬁlter optimization cannot be used, since there is no unique hash value. Instead, all trees must be accessed separately.</p>]]></content>
    
    
      
      
        
        
    <summary type="html">&lt;p&gt;[TOC]&lt;/p&gt;
&lt;h1 id=&quot;Ch24-Advanced-Indexing-Techniques&quot;&gt;&lt;a href=&quot;#Ch24-Advanced-Indexing-Techniques&quot; class=&quot;headerlink&quot; title=&quot;Ch24</summary>
        
      
    
    
    
    <category term="Database" scheme="https://www.virgilsun.com/categories/Database/"/>
    
    
    <category term="Indexing" scheme="https://www.virgilsun.com/tags/Indexing/"/>
    
  </entry>
  
  <entry>
    <title>Notes on Database System Concepts - Ch13</title>
    <link href="https://www.virgilsun.com/Notes%20on%20Database%20System%20Concepts%20-%20Ch13%20Storage/"/>
    <id>https://www.virgilsun.com/Notes%20on%20Database%20System%20Concepts%20-%20Ch13%20Storage/</id>
    <published>2021-12-05T16:00:00.000Z</published>
    <updated>2021-12-06T13:27:51.679Z</updated>
    
    <content type="html"><![CDATA[<p>[TOC]</p><p>This series of blogs record notes on indexing and queries in Database System Concepts, 7th edition, thus mainly on RDBMS.</p><h1 id="Ch13-Data-Storage-Structures"><a href="#Ch13-Data-Storage-Structures" class="headerlink" title="Ch13 Data Storage Structures"></a>Ch13 Data Storage Structures</h1><p>Persistence to disk. Though DB is based on FS, it still needs to be aware of blocks (pages) from underlying storage to support recovery from failure.</p><h2 id="13-2-File-Organization"><a href="#13-2-File-Organization" class="headerlink" title="13.2 File Organization"></a>13.2 File Organization</h2><p>File: logically sequence as series of records, partitioned into fixed-length storage units called <strong>blocks</strong>.</p><h3 id="13-2-1-Fixed-Length-Records"><a href="#13-2-1-Fixed-Length-Records" class="headerlink" title="13.2.1 Fixed-Length Records"></a>13.2.1 Fixed-Length Records</h3><p>A table with fixed row size.</p><ul><li><p>Two issues:</p><ol><li>cross-block records: so long as the block size is not a multiple of row size, part of the record will be stored in former block while the rest part in the latter.</li><li>How to delete: space occupied by a deleted record should be filled with another record.</li></ol></li><li><p>Solutions:</p><ol><li><p>Keep remaining space (less than row size) empty</p></li><li><p>Use <strong>free list</strong> to record deleted records: File header records the address of the first deleted records,  one deleted record points to the next one, thus forming a list.</p><p><img src="https://s2.loli.net/2021/12/06/OZdxSPlW4jUB2Hh.png" alt="free_list"></p></li></ol></li></ul><h3 id="13-2-2-Variable-Length-Records"><a href="#13-2-2-Variable-Length-Records" class="headerlink" title="13.2.2 Variable-Length Records"></a>13.2.2 Variable-Length Records</h3><ol><li><p>How to represent a single record with variable-length: initial fixed-length part (content + meta) + variable-length attribute content</p><p><img src="https://s2.loli.net/2021/12/06/yFzuXRiK6hsY9xp.png" alt="record_representation"></p><ul><li>initial fixed-length part<ul><li><offset, length> pair: indicating position and size for variable-length attribute</li><li>fixed-length attribute value</li><li><strong>null bitmap</strong>: indicating null value</li></ul></li><li>variable-length content</li></ul></li><li><p>How to store variable-length records in a block: <strong>slotted-page structure</strong></p><p><img src="https://s2.loli.net/2021/12/06/OqGyzwFg2n6bvoR.png" alt="image.png"></p><ul><li><p>block header</p><ul><li># records</li><li>pointer: end of free space</li><li>array whose entris contain <location, size> of each record</li></ul></li><li><p>free space: between header and records</p></li><li><p>actual records:</p><ul><li>allocated contiguously in the block, starting from the end of the block.</li><li>insertion: allocate space in free space</li><li>deletion (same for recod growing/shrinking): mark entry, move frontier transactions to cover deleted space.</li><li>pointers can’t point to records, but to entries.</li></ul></li><li><p>:question:</p><ul><li>For deletion, the space of the deleted record is occupied by moving frontier transactions, but its entry is just marked as delete. Is this because, entry is fixed-length, s.t. it can be reused for later insertion so we don’t delete it, but record is variable-length so we delete it and move other records to cover it?</li></ul></li></ul></li></ol><h2 id="13-3-Organization-of-Records-in-Files"><a href="#13-3-Organization-of-Records-in-Files" class="headerlink" title="13.3 Organization of Records in Files"></a>13.3 Organization of Records in Files</h2><ul><li>Heap: no order</li><li>Sequential: stored in sequential order according the value of a search key</li><li>Multitable clustering: records from different relation/table are stored in the same block, to reduce the cost of certain join operations.</li><li>B+-tree: provide ordered access, and efficient point query (Ch 14.4.1).</li><li>Hashing (Ch 14.5).</li></ul><h3 id="13-3-1-Heap-File-Organization"><a href="#13-3-1-Heap-File-Organization" class="headerlink" title="13.3.1 Heap File Organization"></a>13.3.1 Heap File Organization</h3><p>Stored in an unordered manner, free up the space of deleted records to store future inserted records. Most databases use a space-efficient data structure called a <strong>free-space map</strong> to track which blocks have free space to store records.</p><p>It’s commonly represented by an array containing 1 entry for each block, and the entry represents the occupancy fraction $f$ that at least a fraction $f$ of the space in the block is free. PostgreSQL, for example, an entry is 1 byte, thus storing number $x=0$ to $255$,  representing occupancy fraction $f=\frac{x}{256}$.</p><p>Can build second-level free-space map where each second-level entry stores the maximum value among multiple blocks.</p><h3 id="13-3-2-Sequential-File-Organization"><a href="#13-3-2-Sequential-File-Organization" class="headerlink" title="13.3.2 Sequential File Organization"></a>13.3.2 Sequential File Organization</h3><p>It’s designed for efficient processing of records in sorted order based on some <strong>search key</strong>. Each records are chained by pointers pointing to the next record in search-key order. To minimize # block accesses in sequential file processing, we store records <em>physically</em> close to the search key order.</p><ul><li>deletion: use pointer chains</li><li>insertion: apply following 2 rules<ol><li>Locate the record in the ﬁle that comes before the record to be inserted in search-key order.</li><li>If there is free space within the same block, insert there; otherwise, insert in an <em>overflow block</em>. In either case, adjust pointers to chain together in search-key order.</li></ol></li></ul><p>Need to be reorganized from time to time, s.t. physical order matches search-key order.</p><h2 id="13-5-Database-Buffer"><a href="#13-5-Database-Buffer" class="headerlink" title="13.5 Database Buffer"></a>13.5 Database Buffer</h2><p>Since database data reside primarily on disk and disk access is much slower, a major goal of DB is to minimize # block transfers between the disk and memory. To do so, one way is to keep as many blocks as possible in memory. The goal is to maximize the chance that when accessing a block, it’s already in memory.</p><p><strong>Buffer</strong>: part of main memory available for storage of copies of disk blocks. The subsystem responsible for the allocation of buﬀer space is called the <strong>buﬀer manager</strong>.</p><h3 id="13-5-1-Buffer-Manager"><a href="#13-5-1-Buffer-Manager" class="headerlink" title="13.5.1 Buffer Manager"></a>13.5.1 Buffer Manager</h3><h4 id="13-5-1-1-Buffer-replacement-strategy"><a href="#13-5-1-1-Buffer-replacement-strategy" class="headerlink" title="13.5.1.1 Buffer replacement strategy"></a>13.5.1.1 Buffer replacement strategy</h4><p>When a new block comes in and there is no room in memory, an old block must be <strong>evicted</strong>. Most OS use LRU scheme, and it can be improved on for DB applications (Ch13.5.2)</p><h4 id="13-5-1-2-Pinned-blocks"><a href="#13-5-1-2-Pinned-blocks" class="headerlink" title="13.5.1.2 Pinned blocks"></a>13.5.1.2 Pinned blocks</h4><p>It’s similar to concurreny control. A block should not be evicted when the DB process is reading/writing it. To do so, <strong>pin</strong> a block s.t. it can’t be evicted by buffer manager, and <strong>unpin</strong> it when finsh operation. For multiprocess, use <strong>pin count</strong> fir each buffer block, s.t. it can’r be evicted by buffer manager unless count equals to 0.</p><h4 id="13-5-1-3-Shared-and-Exclusive-Locks-on-Buffer"><a href="#13-5-1-3-Shared-and-Exclusive-Locks-on-Buffer" class="headerlink" title="13.5.1.3 Shared and Exclusive Locks on Buffer"></a>13.5.1.3 Shared and Exclusive Locks on Buffer</h4><p>Shared block (read only) &amp; exclusive lock (write), detailed locking in Ch 18.</p><p>Work flow: pin, get lock, operate, release lock, unpin.</p><h3 id="13-5-2-Buffer-Replacement-Strategies"><a href="#13-5-2-Buffer-Replacement-Strategies" class="headerlink" title="13.5.2 Buffer-Replacement Strategies"></a>13.5.2 Buffer-Replacement Strategies</h3><p>LRU: based on a general assumption that a recently referenced block tends to be referenced again. It’s acceptable for OS not DB, since DB can predict the patter nof future references more accurately by looking the several steps compromised the user request.</p><p>E.g. MRU for join operation. E.g. prefer to remove record block instead of index blocks since latter are more frequently accessed. No single strategy is known that handles all the possible scenarios well.</p><h2 id="13-6-Column-Oriented-Storage"><a href="#13-6-Column-Oriented-Storage" class="headerlink" title="13.6 Column-Oriented Storage"></a>13.6 Column-Oriented Storage</h2><p>Each attribute is stored in a separate file. Each file is compressed.</p><p>Thus, it is not suitable for queries that fetch multiple attributes from a few rows of a relation. However, column-oriented storage is well suited for data analysis queries, which process many rows of a relation, but often only access some of the attributes. Reasons are listed below:</p><ul><li>Reduced I/O. In contrast, in row-oriented storage, irrelevant attributes are fetched from disk.</li><li>Improved CPU cache performance. Similar to reduced I/O reduce cost from disk to memory, cost from memory to CPU cache is also reduced by avoiding loading irrelevant attributes.</li><li>Improved compression. Effectiveness of compression is significantly increased when storing values of the same type together, compared to different types in row-oriented storage. :question: Details on compression.</li><li>Vector processing. Modern CPU supports <strong>vector processing</strong>, i.e. a CPU operation can be applied in parallel on a number of elements of an array. Column-oriented storage allows vector processing like comparing an attribute with a constant, which is important in selection condition. It also enables aggregating multiple values in parallel.</li></ul><p>Indexing and query processing should be carefully designed to benefit from column-oriented storage (Ch 14.9).</p><p>Drawbacks, unsuitable for transaction processing:</p><ul><li>Cost of tuple reconstruction.</li><li>Cost of tuple deletion and update.</li><li>Cost of decompression.</li></ul><p>E.g. <strong>Apache ORC</strong> (Optimized Row Columnar) are columnar file representation.</p><h2 id="13-7-Storage-Organization-in-Main-Memory-Databases"><a href="#13-7-Storage-Organization-in-Main-Memory-Databases" class="headerlink" title="13.7 Storage Organization in Main-Memory Databases"></a>13.7 Storage Organization in Main-Memory Databases</h2><p>A <strong>main-memory database</strong> is a database where all data reside in memory.</p><p>With disk-based DB, a record pointer consist of a block identifier and offset within the block. First need to check if block is in buffer (usually done by in-memory hash index), if it is, find location; if not fetch from disk. Time consuming. In contrast, main-memory DB can directly point to memory.</p>]]></content>
    
    
      
      
        
        
    <summary type="html">&lt;p&gt;[TOC]&lt;/p&gt;
&lt;p&gt;This series of blogs record notes on indexing and queries in Database System Concepts, 7th edition, thus mainly on</summary>
        
      
    
    
    
    <category term="Database" scheme="https://www.virgilsun.com/categories/Database/"/>
    
    
    <category term="Storage" scheme="https://www.virgilsun.com/tags/Storage/"/>
    
  </entry>
  
  <entry>
    <title>Notes on Database System Concepts - Ch14 Indexing</title>
    <link href="https://www.virgilsun.com/Notes%20on%20Database%20System%20Concepts%20-%20Ch14%20Indexing/"/>
    <id>https://www.virgilsun.com/Notes%20on%20Database%20System%20Concepts%20-%20Ch14%20Indexing/</id>
    <published>2021-12-05T16:00:00.000Z</published>
    <updated>2021-12-09T03:15:25.741Z</updated>
    
    <content type="html"><![CDATA[<p>[TOC]</p><h1 id="Ch14-Indexing"><a href="#Ch14-Indexing" class="headerlink" title="Ch14 Indexing"></a>Ch14 Indexing</h1><p>Many queries reference only a small proportion of records, like where condition, it’s insufficient to read every tuple. Ideally, it shall be able to locate these records directly.</p><h2 id="14-1-Basic-Concepts"><a href="#14-1-Basic-Concepts" class="headerlink" title="14.1 Basic Concepts"></a>14.1 Basic Concepts</h2><p>Two basic kindes of indices:</p><ul><li>Order indices: Based on a sorted ordering of the value</li><li>Hash indices: Based on a uniformly distribution of value across a range of buckets.</li></ul><p>No one technique is the best. Rather, each technique is best suited to particular database applications. Each technique must be evaluated on the basis of these factors:</p><ul><li>Access types: E.g. point query, range query.</li><li>Access time.</li><li>Insertion time: time to find the corect location to insert new item, and time to update the index structure.</li><li>Deletion time: time to find the item to be deleted, and time to update the index structure.</li><li>Space overhead.</li></ul><p>We often want to have more than one index for a ﬁle on different attributes.</p><h2 id="14-2-Ordered-Indices"><a href="#14-2-Ordered-Indices" class="headerlink" title="14.2 Ordered Indices"></a>14.2 Ordered Indices</h2><p><strong>index entry</strong>: a search-key value + pointers to one or more records with that value as their search-key value.</p><ul><li><p>primary vs. secondary index</p><ul><li><p><strong>clustering index</strong> (<strong>primary index</strong>): search key also defines the sequential order of the file (<strong>index-sequential file</strong>).</p></li><li><p><strong>nonclustering index</strong> (<strong>secondary index</strong>): search key speciﬁes an order diﬀerent from the sequential order of the ﬁle.</p></li></ul></li></ul><h3 id="14-2-1-Dense-and-Sparse-Indices"><a href="#14-2-1-Dense-and-Sparse-Indices" class="headerlink" title="14.2.1 Dense and Sparse Indices"></a>14.2.1 Dense and Sparse Indices</h3><ul><li>dense vs. sparse index<ul><li><strong>dense index</strong>: an index entry appears for every search-key value in the file.<ul><li>In a dense clustering index, the index entry contains one pointer to the first record with that search-key value, where the rest records are stored sequentially after it.</li><li>In a dense nonclustering index, the index entry must store a list of pointers to all records with the same search-key value.</li></ul></li><li><strong>sparse index</strong>: an index entry appears for only some of the searchkey values. Sparse indices can be used only if the relation is stored in sorted order of the search key; that is, if the index is a clustering index.</li><li>pros:<ul><li>dense index: faster access time</li><li>sparse index: less space, less maintenance cost for insertions and deletions.</li></ul></li></ul></li></ul><p>It’s a trade off between access time and space overhead. A good compromise is to have a sparse index with one index entry per block since the dominant cost in processing a database request is the time that it takes to bring a block from disk into main memory. Once we have brought in the block, the time to scan the entire block is negligible.</p><p>However, if the record is in overflow block, it takes extra block access.</p><h3 id="14-2-2-Multilevel-Indices"><a href="#14-2-2-Multilevel-Indices" class="headerlink" title="14.2.2 Multilevel Indices"></a>14.2.2 Multilevel Indices</h3><p>Index file can also be too large to fit in the memory thus requiring loading from disk. Binary search can be used on the index file to locate the entry, but the search still has a large cost $\lceil\log_2(b)\rceil$, where $b$ denotes # blocks the index occupies.</p><p>Building multilevel indices with $m$ fan-out, can reduce to $\lceil\log_m(b)\rceil$. Note that the index entries are always in sorted order, allowing the outer index to be sparse.</p><h3 id="14-2-3-Index-Update"><a href="#14-2-3-Index-Update" class="headerlink" title="14.2.3 Index Update"></a>14.2.3 Index Update</h3><p>Treat update as deletion and insertion. For index-sequential files.</p><h4 id="14-2-3-1-Insertion"><a href="#14-2-3-1-Insertion" class="headerlink" title="14.2.3.1 Insertion"></a>14.2.3.1 Insertion</h4><p>First, the system performs a lookup using the search-key value that appears in the record to be inserted.</p><ul><li>Dense indices<ol><li>If the search-key value doesn’t appear in the index, inserts an index entry at the appropriate position.</li><li>Else (index already has this search-key value)<ol><li>If the index entry stores pointers to all records with the same search-key, adds a new pointer to the new record.</li><li>Else if the index entry only stores a pointer to the first record, place the new record after other records with the same value.</li></ol></li></ol></li><li>Sparse indices: Assume the index stores an entry for each block.<ol><li>If a new block is created: insert the first search-key value in the new block into the index</li><li>If the new record update the least search-key in its block: update the index entry</li><li>Else, no change.</li></ol></li></ul><h4 id="14-2-3-2-Deletion"><a href="#14-2-3-2-Deletion" class="headerlink" title="14.2.3.2 Deletion"></a>14.2.3.2 Deletion</h4><p>To delete a record, the system ﬁrst looks up the record to be deleted.</p><ul><li>Dense indices<ol><li>the deleted record is the only record with this search-key value</li><li>Else (multiple records with this search-key value)<ol><li>If the entry stores pointers to all records: delete the pointer to the record to be deleted.</li><li>Else if the entry only stores a pointer to the first record: only update this index entry when the record to be deleted is the first record, and point to the second one.</li></ol></li></ol></li><li>Sparse indices<ol><li>If index doesn’t contain any entry with the search key value of the deleted record: no change.</li><li>Else (appear in entry)<ol><li>If the deleted record is the only record with its search key: replace the index record with an index record with the next search-key value; if the next already has index entry, just delete instead of being replaced.</li><li>Else (multiple records with same search-key): update to the second record with same key.</li></ol></li></ol></li></ul><h3 id="14-2-4-Secondary-Indices"><a href="#14-2-4-Secondary-Indices" class="headerlink" title="14.2.4 Secondary Indices"></a>14.2.4 Secondary Indices</h3><p>Secondary indices must be dense, with an index entry for every search-key value, and a pointer to every record in the ﬁle. </p><ul><li>On a candidate key:<ul><li>like a dense clustering index, bur records are not sequentially stored.</li></ul></li><li>Not a candidate key:<ul><li><strong>nonunique search key</strong>: If a relation can have more than one record containing the same search key value.</li><li>One implementation: the secondary index entry contains a pointer to a bucket that contain pointers to those records.<ul><li>Drawbacks:<ul><li>Longer access time: since it introduces an extra level of indirection.</li><li>May waste space: If a key has few/no duplicates, if a bucket is assigned with a whole block.</li></ul></li></ul></li></ul></li></ul><p>Sequential scan in secondary-key order can be low.</p><p>Insertion and deletion in Ch14.2.3 applies to secondary index with actions for dense indices storing pointers for all records.</p><p>Secondary indices improve the performance of queries with keys other than the clustering index, but impose a significant overhead on modification. Deciding which secondary indices are desirable should be based on estimation of the relative frequency of queries and modifications.</p><h3 id="14-2-5-Indices-on-Multiple-Keys"><a href="#14-2-5-Indices-on-Multiple-Keys" class="headerlink" title="14.2.5 Indices on Multiple Keys"></a>14.2.5 Indices on Multiple Keys</h3><p><strong>composite search key</strong>: A search key containing more than one attribute.</p><p><strong>lexicographic ordering</strong>: Determine orderings for composite search key, i.e. a tuple of values .For example, for the case of two attribute search keys, $(a_1, a_2 ) &lt; (b_1, b_2)$ if either $a_1 &lt; b_1$ or $a_1 = b_1$ and $a_2 &lt; b_2$.</p><h2 id="14-3-B-Tree-Index-Files"><a href="#14-3-B-Tree-Index-Files" class="headerlink" title="14.3 B+-Tree Index Files"></a>14.3 B+-Tree Index Files</h2><p><strong>B+-tree index</strong></p><ul><li>balanced tree: every path from the root to a leaf is of equal length</li><li>nonleaf node<ul><li>other than the root: has between $\lceil n/2 \rceil$ and $n$ children, where $n$ is fixed for a particular tree.</li><li>root: has between $2$ and $n$ children.</li></ul></li></ul><p>cons: extra insertion and deletion overhead, space overhead. But the advantages of B+-tree outweigh disadvantages.</p><h3 id="14-3-1-Structure-of-a-B-Tree"><a href="#14-3-1-Structure-of-a-B-Tree" class="headerlink" title="14.3.1 Structure of a B+-Tree"></a>14.3.1 Structure of a B+-Tree</h3><p>Assume no duplicate search key values; we consider the issue of nonunique search keys later.</p><p><strong>Node structure</strong></p><ul><li>$n-1$ search-key values $K_1,K_2,…,K_{n-1}$: in sorted order</li><li>$n$ pointers $P_1,P_2,…,P_n$</li></ul><p><img src="https://s2.loli.net/2021/12/07/yJPiOeaF9CGTu2t.png" alt="B+tree_node"></p><p><strong>Leaf node</strong></p><ul><li>Search-key values<ul><li>Each leaf node can have between $\lceil (n-1)/2 \rceil$ and $n-1$ search-key values</li><li>For 2 leaf nodes $L_i, L_j$ where $i&lt;j$, then every search-key value in $L_i$ is smaller than every search-key value in $L_j$.</li></ul></li><li>Pointers:<ul><li>$P_i$, where $i=1,2,…,n-1$, points to a file record with search-key value $K_i$.</li><li>$P_n$ points to the next leaf node thus forming a chain in search-key order.</li></ul></li></ul><p><strong>Nonleaf node</strong> (<strong>internal node</strong>)</p><ul><li>Pointers<ul><li>$P_i$ points to tree nodes containing those search-key values  $[K_{i-1},K_i)$. In other words, $K_i$ equals to the minimal value in the part pointed by $P_{i+1}$.</li><li>a nonleaf node has between $\lceil n/2 \rceil$ and $n$ pointers.</li><li><em>fanout</em>: # pointers in a node</li></ul></li></ul><p>To solve duplicated serach-key value, can have pointers for every record or point to a bucket. Most DB implementations solve nonuniqueness by coupling with the primary key: if search key $a_i$ of relation $r$ is nonunique, let $A_i$ be the primary key, use $(a_i,A_i)$ instead of $a_i$ as search key.</p><h3 id="14-3-2-Queries-on-B-Trees"><a href="#14-3-2-Queries-on-B-Trees" class="headerlink" title="14.3.2 Queries on B+-Trees"></a>14.3.2 Queries on B+-Trees</h3><p><strong>point query</strong>: all the way down leaf node, and point to the file record.</p><p>B+-tree supports <strong>range query</strong> on $[lb,ub]$, by point query $lb$, and traverse on leaf nodes until $ub$.</p><p>Query cost</p><ul><li>root to leaf: If there are N records in the ﬁle, the path is no longer than $\lceil \log_{\lceil n/2 \rceil} (N) \rceil$.<ul><li>Difference between B+-tree and in-memory tree (such as binary tree): size of a node (Fanout), and as a result, the height of the tree.</li></ul></li><li>leaf query:<ul><li>point query: 1 more random I/O operation</li><li>range query:<ul><li>cost to fetch multiple leaf nodes</li><li>cost to access file block, cost depends on whether it’s a index-sequential file.</li></ul></li></ul></li></ul><p>To avoid duplication, the same as in Ch14.3.1 with composite keys as $(a_i, A_i)$. Issue: how to query all records for a certain value $a_i=v$? Solution: use range query on $[(v,-\infty), (v, \infty)]$.</p><h3 id="14-3-3-Updates-on-B-Trees"><a href="#14-3-3-Updates-on-B-Trees" class="headerlink" title="14.3.3 Updates on B+-Trees"></a>14.3.3 Updates on B+-Trees</h3><p>Consider only insertion and deletion, which may cause to <strong>split</strong> a node or <strong>coalesce</strong> nodes.</p><h4 id="14-3-3-1-Insertion"><a href="#14-3-3-1-Insertion" class="headerlink" title="14.3.3.1 Insertion"></a>14.3.3.1 Insertion</h4><p>If a leaf node is already full, after insertion it shall be splitted. a new leaf node should create a new entrey in its parent node, and may cause spliting in cascade.</p><h4 id="14-3-32-Deletion"><a href="#14-3-32-Deletion" class="headerlink" title="14.3.32 Deletion"></a>14.3.32 Deletion</h4><p>If after deletion, # search keys in the leaf node $&lt;\lceil (n-1)/2 \rceil$, either merge the node with a sibling node or redistribute the entries between the nodes, to ensure that each node is at least half-full.</p><h3 id="14-3-4-Complexity-of-B-Tree-Updates"><a href="#14-3-4-Complexity-of-B-Tree-Updates" class="headerlink" title="14.3.4 Complexity of B+-Tree Updates"></a>14.3.4 Complexity of B+-Tree Updates</h3><p>Insertion and deletion operations arecomplicated, they require relatively few I/O operations.</p><h2 id="14-4-B-Tree-Extensions"><a href="#14-4-B-Tree-Extensions" class="headerlink" title="14.4 B+-Tree Extensions"></a>14.4 B+-Tree Extensions</h2><h3 id="14-4-1-B-Tree-File-Organization"><a href="#14-4-1-B-Tree-File-Organization" class="headerlink" title="14.4.1 B+-Tree File Organization"></a>14.4.1 B+-Tree File Organization</h3><p>As mentioned in Section 14.3, the main drawback of index-sequential ﬁle organization is the degradation of performance as the ﬁle grows: With growth, an increasing percentage of index entries and actual records become out of order and are stored in overﬂow blocks. We solve the degradation of index lookups by using B+-tree indices on the ﬁle.</p><p><strong>B+-tree file organization</strong></p><ul><li>leaf node: store records, instead of storing pointers to records.</li></ul><h3 id="14-4-2-Secondary-Indices-and-Record-Relocation"><a href="#14-4-2-Secondary-Indices-and-Record-Relocation" class="headerlink" title="14.4.2 Secondary Indices and Record Relocation"></a>14.4.2 Secondary Indices and Record Relocation</h3><p>Some ﬁle organizations, such as the B + -tree ﬁle organization, may change the location of records even when the records have not been updated like spliting and coalescing.</p><p>A widely used solution for this problem is as follows: In secondary indices, in place of pointers to the indexed records, we store the values of the primary-index search-key attributes.</p><p>Thus relocation of records doesn’t requrie updates on secondary indices. And the query on secondary index now requires 2 steps: query secondary index to find primary key, query parimary index to locate record.</p><h3 id="14-4-3-Indexing-Strings"><a href="#14-4-3-Indexing-Strings" class="headerlink" title="14.4.3 Indexing Strings"></a>14.4.3 Indexing Strings</h3><p>Creating B + -tree indices on string-valued attributes raises two problems:</p><ol><li>Strings can be of variable length, thus nodes may have different fanouts.</li><li>Strings can be long, leading to a low fanout and a correspondingly increased tree height.</li></ol><p>To increase the fanout, use <strong>prefix compression</strong>, i.e. don’t store entire search-key value at nonleaf nodes but only a prefix that is sufficient to distinguish between the key values in the subtree.</p><h3 id="14-4-4-Bulk-Loading-of-B-Tree-Indices"><a href="#14-4-4-Bulk-Loading-of-B-Tree-Indices" class="headerlink" title="14.4.4 Bulk Loading of B+-Tree Indices"></a>14.4.4 Bulk Loading of B+-Tree Indices</h3><p><strong>bulk loading</strong>: Insertion of a large number of entries at a time into an index.</p><p>Solution:</p><ol><li>Create flat file containing index entries.</li><li>Sort the file on the search-key of the index being constructed.</li><li>Scan the sorted file and insert into the index.</li></ol><p>There is a signiﬁcant beneﬁt to sorting the entries before inserting them into the B +-tree. When the entries are inserted in sorted order, all entries that go to a particular leaf node will appear consecutively, and the leaf needs to be written out only once; nodes will never have to be read from disk during bulk load, if the B + -tree was empty to start with.</p><p><strong>bottom-up B +tree construction</strong>: If the B + -tree is initially empty, it can be constructed faster by building it bottom-up, from the leaf level, instead of using the usual insert procedure. After sorting the entries as we just described, we break up the sorted entries into blocks, keeping as many entries in a block as can ﬁt in the block; the resulting blocks form the leaf level of the B +-tree.</p><p>Some database systems recommend that if a very large number of tuples are added at once to an already existing relation, indices on the relation (other than any index on the primary key) should be dropped, and then re-created after the tuples are inserted, to take advantage of eﬃcient bulk-loading techniques.</p><h3 id="14-4-6-Indexing-on-Flash-Storage"><a href="#14-4-6-Indexing-on-Flash-Storage" class="headerlink" title="14.4.6 Indexing on Flash Storage"></a>14.4.6 Indexing on Flash Storage</h3><p>:star:Flash storage is different on writting, which inspires works like LSM tree to reduce erase operations for flash storage.</p><ul><li>Flash storage is structred as pages: smaller than magnetic blocks</li><li>Faster random page read: 20 to 100 microseconds, while 5 to 10 miliseconds with magnetic disk</li><li>Complicated writing operation, heavy cost for <strong>eration operation</strong>: Flash storage doesn’t permit in-placeupdates to data at the physical level. It’s a copy+write of an entire flash-storage page, requiring the old copy of the page to be erased subsequently. A new page can be written in 20 to 100 microseconds, but eventually old pages need to be erased to free up the pages for further writes. :question:Erases are done at the level of blocks containing multiple pages, and a block erase takes 2 to 5 milliseconds.</li></ul><p>Optimum B+-tree node for flash is smaller than magnetic disk. It makes sense for node size to match  page size.</p><p>Several extensions and alternatives to B+-tree have been proposed for flash storage</p><ul><li>target: reducing the number of erase operations that result due to page rewrites.</li><li>solutions (Ch14.8):<ol><li>add buﬀers to internal nodes of B +-trees and record updates temporarily in buﬀers at higher levels, pushing the updates down to lower levels lazily. The key idea is that when a page is updated, multiple updates are applied together, reducing the number of page writes per update.</li><li>Another approach creates multiple trees and merges them; the log-structured merge tree and its variants are based on this idea.</li></ol></li></ul><h3 id="14-4-7-Indexing-in-Main-Memory"><a href="#14-4-7-Indexing-in-Main-Memory" class="headerlink" title="14.4.7 Indexing in Main Memory"></a>14.4.7 Indexing in Main Memory</h3><p>Optimization when B+-tree is used to index in-memory data:</p><ol><li>Since memory is costlier than disk, reduce memory size with techniques in Ch14.4.1</li><li>Cost of I/O is small, thus the tree struture can be relatively deep.</li><li>Speed difference between cache memory and main memory (1 or 2 nanoseconds in cache, while 50 to 100 nanoseconds from main memory): data are transferred in units of <em>cache-line</em> (typically 64 bytes). B + -trees with small nodes that ﬁt in a cache line have been found to provide very good performance with in-memory data, with less cache miss than tall, skinny treelike binary tree and B+-tree with larger nodes.</li><li>For both memory and disk performance: Large nodes are used to optimize disk-based access, but instead of treating data in a node as single large array of keys and pointers, the data within a node are structured as a tree, with smaller nodes that match the size of a cache line.</li></ol><h2 id="14-5-Hash-Indices"><a href="#14-5-Hash-Indices" class="headerlink" title="14.5 Hash Indices"></a>14.5 Hash Indices</h2><p>Hashing is a widely used technique for building indices in main memory; hash ﬁle organizations are not very widely used.</p><p><strong>overﬂow chaining</strong> Hash indexing using overﬂow chaining is also called <strong>closed addressing</strong> (or, less commonly, closed hashing).</p><p>:star: An alternative hashing scheme called open addressing is used in some applications, but is not suitable for most database indexing applications since open addressing does not support deletes eﬃciently.</p><p>Hash index support equality query, but don’t support range query.</p><p><strong>Static hashing</strong>: # buckets is fixed</p><p><strong>Dynamic hashing</strong> Ch24.5</p><h2 id="14-6-Multiple-Key-Access"><a href="#14-6-Multiple-Key-Access" class="headerlink" title="14.6 Multiple-Key Access"></a>14.6 Multiple-Key Access</h2><h3 id="14-6-1-Using-Multiple-Single-Key-indices"><a href="#14-6-1-Using-Multiple-Single-Key-indices" class="headerlink" title="14.6.1 Using Multiple Single-Key indices"></a>14.6.1 Using Multiple Single-Key indices</h3><p>Equality query on 2 indices, optimal strategy is to do 2 separate equality queries and take the intersection of 2 result sets.</p><p>However, it maybe a poor choice if all of the following holds</p><ol><li>Too many records on both separate equality query results.</li><li>Intersections are small.</li></ol><p>Bitmap index can sometimes greatly speed up such intersection.</p><h3 id="14-6-2-Indices-on-Multiple-Keys"><a href="#14-6-2-Indices-on-Multiple-Keys" class="headerlink" title="14.6.2 Indices on Multiple Keys"></a>14.6.2 Indices on Multiple Keys</h3><p>An alternative is to combine those 2 attributes into one index.</p><p>Shortcoming when query on first attribute is not equality.</p><p><em>R-tree</em> can be used to handle indexing on multiple dimensions and is discussed in Ch 14.10.1.</p><h3 id="14-6-3-Covering-Indices"><a href="#14-6-3-Covering-Indices" class="headerlink" title="14.6.3 Covering Indices"></a>14.6.3 Covering Indices</h3><p><strong>Covering indices</strong> are indices that store the values of some attributes (other than the search-key attributes) along with the pointers to the record. Storing extra attribute values is useful with secondary indices, since they allow us to answer some queries using just the index, without even looking up the actual records.</p><h2 id="14-8-Write-Optimized-Index-Structures"><a href="#14-8-Write-Optimized-Index-Structures" class="headerlink" title="14.8 Write-Optimized Index Structures"></a>14.8 Write-Optimized Index Structures</h2><p>Now suppose writes or inserts are done in an order that does not match the sort order of the index. Then, each write/insert is likely to touch a diﬀerent leaf node; if the number of leaf nodes is signiﬁcantly larger than the buﬀer size, most of these leaf accesses would require a random read operation, as well as a subsequent write operation to write the updated leaf page back to disk.</p><p>For flash based SSD, though random I/O is faster, each page write still has a significant cost for page earse. Thus the basic B+-tree structure is not ideal for applications with a very large number of random writes/inserts per second.</p><h3 id="14-8-1-LSM-Trees"><a href="#14-8-1-LSM-Trees" class="headerlink" title="14.8.1 LSM Trees"></a>14.8.1 LSM Trees</h3><p>in-memory tree $L_0$, on-disk trees $L_1,…,L_k$, where $k$ is called the level.</p><p><strong>Insertion</strong></p><ol><li>$L_0$ not full, insert in $L_0$</li><li>Else, flush to $L_1$ on disk<ol><li>$L_1$ is empty: $L_0$ is written to disk to create the initial $L_1$</li><li>Else: scan leaf nodes of both $L_0, L_1$ in increasing key order, and merge them where a new B+-tree is created on those merged entries from a bottom-up build process. The new $L_1$ replaces the old one.</li></ol></li></ol><ul><li>Benefits<ul><li>Leaves of the new tree are sequentially located, avoiding random I/O during subsequent merges.</li><li>Leaves are full, avoiding the overhead of partially occupied leaves that can occur with page splits.</li></ul></li><li>If only $L_1$, each time entire content is copied to merge with $L_0$. To reduce the cost:<ul><li>Multiple level: $k&gt;1$</li><li><strong>Stepped-merge index</strong>: Each level can have up to $b&gt;1$ trees.<ul><li>It reduces the insert cost, but increases query cost, since multiple trees need to be searched.</li><li>Solution: Bitmap-based structures called <strong>Bloom ﬁlters</strong> (Ch24.1), are used to reduce the number of lookups by eﬃciently detecting that a search key is not present in a particular tree. Bloom ﬁlters occupy very little space, but they are quite eﬀective at reducing query cost.</li></ul></li></ul></li></ul><p><strong>Deletion</strong></p><p>Instead of direct deletion, insert a new <strong>deletion entry</strong>:</p><ul><li>Lookup: among merged records, if there are both an index entry and a delete entry of the same key, they are filtered out and not returned as the result.</li><li>Merge: When trees are merged, index entry and delete entry with same key value are both discarded.</li></ul><p><strong>Update</strong></p><p>Similar to delete, insert a new <strong>update entry</strong>. Lookup return the latest value, and merge applies the updates and discard update entries.</p><p><strong>Design purpose</strong></p><p>LSM trees were initially designed to reduce the write and seek overheads of magnetic disks. The beneﬁt of avoiding random I/O that LSM tree variants provide is not particularly important with SSDs.</p><p>However, recall that ﬂash memory does not allow in-place update, and writing even a single byte to a page requires the whole page to be rewritten to a new physical location; the original location of the page needs to be erased eventually, which is a relatively expensive operation. <strong>The reduction in number of writes using LSM tree variants</strong>, as compared to traditional B + -trees, can provide substantial performance beneﬁts when LSM trees are used with SSDs.</p><p>A variant of the LSM tree similar to the stepped-merge index, with multiple trees in each layer, was used in Google’s BigTable system, as well as in Apache HBase, the open source clone of BigTable. These systems are built on top of distributed ﬁle systems that <em>allow appends</em> to ﬁles but <em>do not support updates</em> to existing data. The fact that LSM trees <strong>do not perform in-place update</strong> made LSM trees a very good ﬁt for these systems.</p><h3 id="14-8-2-Buffer-Tree"><a href="#14-8-2-Buffer-Tree" class="headerlink" title="14.8.2 Buffer Tree"></a>14.8.2 Buffer Tree</h3><p>The key idea behind the buﬀer tree is to associate a buﬀer with each internal node (including root) of a B+-tree.</p><p><img src="https://s2.loli.net/2021/12/09/iSuQFqBr74lIvjh.png" alt="image.png"></p><p>Insertion doesn’t traverse to the leaf, but insert in the buffer. When buffer is full, push each index record one level down the tree, recursively.</p><p>Lookup requires chekcing on buffer. Delete and update are similar to LSM.</p><p>Buffer tree have better worst-case complexity bounds on # I/O operations, faster read cost than LSM. But write involve random I/O, requiring more seeks.</p><p>However, since random I/O operations are very eﬃcient on SSDs, and buﬀer trees tend to perform fewer write operations overall compared to LSM trees, buﬀer trees can provide better write performance on SSDs. Several index structures designed for ﬂash storage make use of the buﬀer concept introduced by buﬀer trees.</p><p>Another beneﬁt of buﬀer trees is that the key idea of associating buﬀers with internal nodes, to reduce the number of writes, can be used with any type of tree-structured index. For example, buﬀering has been used as a way of supporting bulk loading of spatial indices such as R-trees (which we study in Section 14.10.1)</p><h2 id="14-9-Bitmap-Indices"><a href="#14-9-Bitmap-Indices" class="headerlink" title="14.9 Bitmap Indices"></a>14.9 Bitmap Indices</h2><ul><li>Sequential record number or block number.</li><li>Discrete attribute, or break up consecutive attribute into multiple levels.</li><li>Each value of attribute has a bitmap, indicating whether it has the value.</li></ul><h2 id="14-10-Indexing-of-Spatial-and-Temporal-Data"><a href="#14-10-Indexing-of-Spatial-and-Temporal-Data" class="headerlink" title="14.10 Indexing of Spatial and Temporal Data"></a>14.10 Indexing of Spatial and Temporal Data</h2><h3 id="14-10-1-Indexing-of-Spatail-Data"><a href="#14-10-1-Indexing-of-Spatail-Data" class="headerlink" title="14.10.1 Indexing of Spatail Data"></a>14.10.1 Indexing of Spatail Data</h3><p><strong>Spatial data</strong> refers to data referring to a point (e.g., (latitude, longitude)) or a region (e.g., identified by a polygon, with each corner’s (latitude, longitude)) in two or higher dimensional space.</p><p>Query:</p><ul><li><strong>range queries</strong>: specified area (multi dimensional)</li><li><strong>nearest neighbor query</strong></li></ul><p><strong>k-d Tree</strong>, <strong>k-d-B Tree</strong>, <strong>R-tree</strong></p><h3 id="14-10-2-Indexing-Temporal-Data"><a href="#14-10-2-Indexing-Temporal-Data" class="headerlink" title="14.10.2 Indexing Temporal Data"></a>14.10.2 Indexing Temporal Data</h3><p>time interval.</p><p><strong>interval B+tree</strong></p>]]></content>
    
    
      
      
        
        
    <summary type="html">&lt;p&gt;[TOC]&lt;/p&gt;
&lt;h1 id=&quot;Ch14-Indexing&quot;&gt;&lt;a href=&quot;#Ch14-Indexing&quot; class=&quot;headerlink&quot; title=&quot;Ch14 Indexing&quot;&gt;&lt;/a&gt;Ch14 Indexing&lt;/h1&gt;&lt;p&gt;Many queries</summary>
        
      
    
    
    
    <category term="Database" scheme="https://www.virgilsun.com/categories/Database/"/>
    
    
    <category term="Indexing" scheme="https://www.virgilsun.com/tags/Indexing/"/>
    
  </entry>
  
  <entry>
    <title>Notes on Rebalancing in the Lightning Network</title>
    <link href="https://www.virgilsun.com/Notes%20on%20Rebalancing%20in%20the%20Lightning%20Network/"/>
    <id>https://www.virgilsun.com/Notes%20on%20Rebalancing%20in%20the%20Lightning%20Network/</id>
    <published>2021-11-23T16:00:00.000Z</published>
    <updated>2021-12-06T13:24:22.138Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Notes-on-Rebalancing-in-the-Lightning-Network"><a href="#Notes-on-Rebalancing-in-the-Lightning-Network" class="headerlink" title="Notes on Rebalancing in the Lightning Network"></a>Notes on Rebalancing in the Lightning Network</h2><h3 id="Payment-Channel"><a href="#Payment-Channel" class="headerlink" title="Payment Channel"></a>Payment Channel</h3><ul><li><p>life cycle</p><ol><li><p><em>funding transaction</em> (on chain)</p><p>A and B open a payment channel $ch_{A,B}$, where one or both commit funds. The total amount is the <em>balance</em> of the shared channel</p></li><li><p>update transactions (off chain)</p><p>no fees, no confirmation delay</p></li><li><p><em>closing transaction</em> (on chain)</p></li></ol></li><li><p>multiple channels</p><p>If A build channels with B, C, and D, she needs to split her money in 3 channels when signing funding transactions, and those splitted funds cannot circulate among different channels.</p><p>If she needs to pay B more than her balance on $ch_{A,B}$, she needs to close $ch_{A,B}$ (later rebuild this channel with larger balance), even other existing channels (to collect money, re-distribute among channels), then rebuild $ch_{A,B}$. It requires plenty of on-chain transactions(funding, closing).</p></li></ul><h3 id="Hashed-TimeLock-Contract-HTLC"><a href="#Hashed-TimeLock-Contract-HTLC" class="headerlink" title="Hashed TimeLock Contract (HTLC)"></a>Hashed TimeLock Contract (HTLC)</h3><p>HTLC enables transactions without a direct channel, but through several chained channels with internal routing nodes.</p><p>HTLC is atomic. (how?)</p><p>HTLC solves the aforementioned problem by introducing routing nodes to handle money distribution among different channels, while users only need to build a single channel with a routing node to transfer with others.</p><h3 id="Rebalancing"><a href="#Rebalancing" class="headerlink" title="Rebalancing"></a>Rebalancing</h3><p>When the transaction surpasses the routing node’s balance on a channel, it needs to rebalance its money among different channels, i.e. rebalancing.</p><p>For example, A (3) —- (3) C (1) —- B (2), A wants to transfer 2 BTC to B, but C doesn’t have sufficient balance on $ch_{C,B}$ to do so. C needs to rebalance, for example, between $ch_{A,C}$ and $ch_{C,B}$.</p><ol><li><p><em>spice in</em></p><p>close $ch_{C,A}$ and reopen it with some funds aside.</p></li><li><p><em>spice out</em></p><p>close $ch_{C,B}$ and reopen it with extra funds.</p></li></ol><p>Both spice operations can be done in a single on-chain transaction.</p><p>Some rebalancing strategies are introduced below:</p><h4 id="Circular-Payments"><a href="#Circular-Payments" class="headerlink" title="Circular Payments"></a>Circular Payments</h4><center class="half">    <img src="https://blog.muun.com/content/images/2018/09/round-A-F-B-C--3--1.svg" width="50%"/><img src="https://blog.muun.com/content/images/2018/09/A-F-B-C--3-.svg" width="50%"/></center><p>It’s a complete off-chain strategy without any on-chain transaction. The whole rebalancing operation is done via payment channels.</p><ul><li><p>Cons</p><ul><li>circle at least comprises 3 nodes, C has to pay other 2 nodes</li><li>the transferable balance is bounded by the minimum value along the circle</li><li>skewness: if B is merchant, all other nodes send to him running out of balance</li></ul></li><li><p>Impacts on <em>routing capacity</em></p><p>Definition: the total amount of BTC a node can send to another one at a given moment.</p><p>Circular payments ensure a circular path that has 2 possible routes to pay. For example, A -&gt; B has two path, A-C-B and A-F-B, with aggregated routing capacity (sum of both paths) unchanged after C’s circular payments.</p><p>Notice: fees are ignored.</p></li></ul><h4 id="Fee-Management"><a href="#Fee-Management" class="headerlink" title="Fee Management"></a>Fee Management</h4><p>Nodes can adjust fee as incentive mechanism s.t. payments tend togo in a favorable direction, where fees can be set as smaller than the alternative path and even offer negative fees. It’s a win-win situation, where B has a discount to use the path, while C gets rebalanced.</p><p>It’s also an off-chain solution. It’s more of an opportunity rather than deliberate control.</p><ul><li>Cons<ul><li>It implies C and B have complete information on current fees</li><li>When there is skewness (B merchant), a discount may not work, and fees may reach negative.</li></ul></li></ul><h4 id="Splicing"><a href="#Splicing" class="headerlink" title="Splicing"></a>Splicing</h4><p>It’s a on-chain strategy mentioned above where a node can close and reopen a channel in a single transaction.</p><ul><li>Cons<ul><li>on chain: pay fees, waiting for confirmation</li></ul></li></ul><p>ref:</p><p>[Rebalancing: The Key to the Lightning Network][<a href="https://blog.muun.com/rebalancing-in-the-lightning-network/">https://blog.muun.com/rebalancing-in-the-lightning-network/</a>]</p><p>[Rebalancing in the Lightning Network: Circular Payments, Fee Management and Splices][<a href="https://blog.muun.com/rebalancing-strategies-overview/">https://blog.muun.com/rebalancing-strategies-overview/</a>]</p>]]></content>
    
    
      
      
        
        
    <summary type="html">&lt;h2 id=&quot;Notes-on-Rebalancing-in-the-Lightning-Network&quot;&gt;&lt;a href=&quot;#Notes-on-Rebalancing-in-the-Lightning-Network&quot; class=&quot;headerlink&quot;</summary>
        
      
    
    
    
    <category term="Blockchain" scheme="https://www.virgilsun.com/categories/Blockchain/"/>
    
    
    <category term="Blockchain" scheme="https://www.virgilsun.com/tags/Blockchain/"/>
    
    <category term="Lightning Network" scheme="https://www.virgilsun.com/tags/Lightning-Network/"/>
    
    <category term="Rebalance" scheme="https://www.virgilsun.com/tags/Rebalance/"/>
    
  </entry>
  
  <entry>
    <title>Modeling the Impact of Network Connectivity on Consensus Security of Proof-of-Work Blockchain</title>
    <link href="https://www.virgilsun.com/Modeling%20the%20Impact%20of%20Network%20Connectivity%20on%20Consensus%20Security%20of%20Proof%20of%20Work%20Blockchain/"/>
    <id>https://www.virgilsun.com/Modeling%20the%20Impact%20of%20Network%20Connectivity%20on%20Consensus%20Security%20of%20Proof%20of%20Work%20Blockchain/</id>
    <published>2021-10-27T16:00:00.000Z</published>
    <updated>2021-11-30T02:29:16.265Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h1><ul><li>Honest-majority security premise comes under two implicit assumptions<ul><li>all nodes have the same communication capability</li><li>all nodes wins in a fork with equal chance</li></ul></li><li><p>Two threat models:</p><ul><li>Honest-but-potentially -colluding:<ul><li>Attackers with propagation advantage can succeed with less than 50% power.</li><li>Qualitative analysis.</li></ul></li><li>Selfish Mining:<ul><li>Strategies like SM utilize the network connectivity.</li><li>Treated as a  preexisting parameter.aaaaaa</li></ul></li></ul></li><li><p>Motivation: quantitative analysis is missed.</p></li></ul><h1 id="Background"><a href="#Background" class="headerlink" title="Background"></a>Background</h1><ul><li>fork: Even all honest miners, there can be a fork due to propagation delay</li><li>longest-chain rule to resolve fork: “assume equal chance”, 50% mines on B1, 50% mines on B2</li><li>well connected nodes exploit intrinsic forks and even cause forks deliberately</li></ul><h1 id="System-Model"><a href="#System-Model" class="headerlink" title="System Model"></a>System Model</h1><h2 id="Network-Model"><a href="#Network-Model" class="headerlink" title="Network Model"></a>Network Model</h2><ul><li>A peer-to-peer network of $N$ nodes: undirected graph $G=(V,E)$</li><li>Adjacency matrix $A$. $A_{i,j}=1$ indicating a connection, thus node $i,j$ can communicate in one hop.</li><li>Mining rate: Poisson process of rate $\pi_i$ per time unit $\delta$.</li></ul><h2 id="Fork"><a href="#Fork" class="headerlink" title="Fork"></a>Fork</h2><p><img src="https://i.loli.net/2021/10/19/Cy9E1GcwaFKfiTL.png" alt="image.png"></p><h2 id="Adversary-Model"><a href="#Adversary-Model" class="headerlink" title="Adversary Model"></a>Adversary Model</h2><ul><li>Honest-but-Potentially-Colluding<ul><li>Metrics: 50% attack threshold (AT50%)</li></ul></li><li>Selfish-Mining: colluding consortium, expand and acquire their power &amp; links.<ul><li>Metrics: AT50%, profitable threshold (PRTH).</li></ul></li></ul><p>idea of collude, expand</p><h1 id="Analysis-on-Honest-Mining"><a href="#Analysis-on-Honest-Mining" class="headerlink" title="Analysis on Honest Mining"></a>Analysis on Honest Mining</h1><h2 id="Fork-rate"><a href="#Fork-rate" class="headerlink" title="Fork rate"></a>Fork rate</h2><ul><li>$M_i$: denotes the event that node $i$ is the first to generate the next block with $P(M_i)=\frac{\pi_i}{\pi}$.</li><li>$U_i(t)$: denotes the set of nodes unaware of node $i$’s block at time $t$.</li><li>$|U_i(t)|_{\pi}$ is the combined block generation rate of $U_i(t)$<ul><li>where $|U_i(0)|_\pi=\pi-\pi_i$</li><li>and $|U_i(t)|_{\pi}=0$ when $t$ exceeds the minimum time needed for $i$’s block to reach all nodes.</li></ul></li><li>$P_{NC,i}(t)$ denotes the probability that the rest network doesn’t generate a competing block by time $t$.<ul><li>$P_{NC,i}(t)=\prod_{s=\delta}^t(1-|U_i(s)|_\pi)$</li></ul></li></ul><h2 id="Mining-Revenue-and-Relative-Mining-Gain"><a href="#Mining-Revenue-and-Relative-Mining-Gain" class="headerlink" title="Mining Revenue and Relative Mining Gain"></a>Mining Revenue and Relative Mining Gain</h2><ul><li><p>Definition of process $\{B_i(h)\}$</p><ul><li>$B_i(h)$ indicates whether node $i$ is the block generator at height $h$</li><li>Mining revenue ($MR_i$): $MR_i=\lim_{H\rightarrow\infty}\frac{1}{H}\sum_{h=1}^HB_i(h)$</li><li>Relative mining gain ($RMG_i$): $RMG_i=\frac{MR_i-\pi_i/\pi}{\pi_i / \pi}$</li></ul></li><li><p>Definition of process $\{W_i(c)\}$:</p><ul><li>$h(c)$: the block height of the $c$-th canonization event.</li><li>$W_i(c)=1$ if $B_i(h(c)+1)=1$.</li></ul></li><li><p>Proposition: $E[W_i]$ at any epoch $c$ can be used to measure $MR_i$ in a conservative manner.</p><ul><li><script type="math/tex; mode=display">E[W_i]=\begin{cases}\leq MR_i & \text{if } E[W_i] \geq \frac{\pi_i}{\pi} \\> MR_i & \text{otherwise}\end{cases}</script></li><li><p>Proof sketch</p><ul><li>any epoch $c$: block generation memoryless, i.i.d. for epochs.</li><li>conservative:<ul><li>if $E[W_i]\geq\frac{\pi_i}{\pi}$, node $i$ has communication advantage to win a fork race.</li><li>if $E[W_i]\geq\frac{\pi_i}{\pi}$, and node $i$ wins block $h(c)+1$, it will continue with an enhanced communication advantage from $h(c)+2$ to $h(c+1)$.</li></ul></li></ul></li></ul></li><li><p>Compute $E[W_i]$ by the law of total expectation</p><ul><li><script type="math/tex; mode=display">E[W_i] = P(M_i)E[W_i|M_i] + \sum_{j\ne i} P(M_j)E[W_i|M_j]</script></li><li><p>Conditional event 1: $W_i|M_i$</p><ul><li><p>no-fork win: node $i$ wins without competing blocks.</p></li><li><p>fork win: rest of the network generate a competing block, whereas node $i$ still wins.</p></li><li><script type="math/tex; mode=display">\begin{align}E[W_i|M_i] &= E[W_i, no-fork|M_i] + E[W_i, fork|M_i] \\&= \lim_{t\rightarrow\infty}P_{NC,i}(t) + \sum_{t=\delta}^\infty P_{NC,i}(t)\sum_{j\in U_i(t)}\pi_j\omega_{i\succ j}(t)\end{align}</script><p>where $\omega_{i\succ j}(t)$ denote when node $j$ generate a competing block at time $t$, the probability that node $i$ wins the fork.</p></li></ul></li><li><p>Conditional event 2: $W_i|M_j$</p><ul><li><script type="math/tex; mode=display">\begin{align}E[W_i|M_j] &= E[W_i, fork|M_j] \\&= \sum_{t=\delta}^\infty P_{NC,j}(t) \pi_i \mathbb{1}_{\{i\in U_j(t)\}}(1-\omega_{j\succ i}(t))\end{align}</script></li></ul></li><li><p>Evaluating $\omega_{i\succ j}(t)$:</p><ul><li><p>$\omega_{i\succ j}(t)$ measures the communication advantage of node $i$ over $j$ when $j$ generates a competing block at time $t$.</p></li><li><p>Define $\tau_{ik}(t)$: the minimal time for $i$’s block propagate to $k$, starting from time $t$.</p></li><li><script type="math/tex; mode=display">\omega_{i \succ j}(t)=\sum_{k} \frac{\pi_k}{\pi}(\mathbb{1}_{\{\tau_ik(t)<\tau_{jk}(0)\}} + \frac{1}{2}\mathbb{1}_{\{\tau_ik(t)=\tau_{jk}(0)\}})</script></li></ul></li></ul></li></ul><h2 id="Security-Analysis"><a href="#Security-Analysis" class="headerlink" title="Security Analysis"></a>Security Analysis</h2><ul><li>lower overall connectivity leads to higher fork rate &amp; lower AT50.<ul><li>higher fork rate: $P_{NC,i}(t)=\prod_{s=\delta}^t(1-|U_i(s)|_\pi)$</li><li>lower AT50: a lower $\lim_{t\rightarrow\infty}P_{NC,i}(t)$ means more revenue is contributed by fork race, which is closely related to communication capability.</li></ul></li><li>high heterogeneous of network connectivity leads to low AT50<ul><li>consider 2 nodes $i$ with high connectivity, $j$ with low connectivity so when there is a fork race, $i$ always harvest, $j$ hardly wins.</li><li>Hence, $E[W_i]&gt;\frac{\pi_i}{\pi}$ while $E[W_j]&lt;\frac{\pi_j}{\pi}$</li></ul></li></ul><h1 id="gamma-amp-SM-Analysis"><a href="#gamma-amp-SM-Analysis" class="headerlink" title="$\gamma$ &amp; SM Analysis"></a>$\gamma$ &amp; SM Analysis</h1><h2 id="SM"><a href="#SM" class="headerlink" title="SM"></a>SM</h2><p><img src="https://i.loli.net/2021/10/29/YAhVnicwmgJSDBG.png" alt="image.png"></p><h2 id="Evaluate-gamma-SM-Using-Betweenness-Centrality"><a href="#Evaluate-gamma-SM-Using-Betweenness-Centrality" class="headerlink" title="Evaluate $\gamma_{SM}$ Using Betweenness Centrality"></a>Evaluate $\gamma_{SM}$ Using Betweenness Centrality</h2><ul><li><p>SM POOL: no internal delay, fully connectedly, incorporate members’ power and outside links.</p></li><li><p>$\gamma$: the fraction of honest miners that choose to mine on SM’s block when there is a fork race.</p></li><li><p>$\sigma(i,j)$: number of shortest paths between $i$ and $j$</p></li><li><p>$\sigma(i,j|SMPOOL)$ number of such paths that pass through SM POOL.</p></li><li><script type="math/tex; mode=display">\gamma_{SM}=\sum_{i\neq SMPOOL}\frac{\pi_i}{\pi-\pi_{SM}}\sum_{j\ne i\ne SMPOOL}\frac{\pi_i}{\pi-\pi_{SM}-\pi_i}\frac{\sigma(i,j|SMPOOL)}{\sigma(i,j)}</script></li></ul><h2 id="Security-Analysis-1"><a href="#Security-Analysis-1" class="headerlink" title="Security Analysis"></a>Security Analysis</h2><ul><li>lower overall connectivity leads to higher $\gamma_{SM}$, lower AT50 and PRTH<ul><li>SM POOL is an influential pool well connected to honest nodes, even delay gets larger it still resides in the shortest path.</li></ul></li><li>Heterogeneous topology may utilized by SM to incorporate influential nodes.</li></ul><h1 id="Evaluation"><a href="#Evaluation" class="headerlink" title="Evaluation"></a>Evaluation</h1><h2 id="Setting"><a href="#Setting" class="headerlink" title="Setting"></a>Setting</h2><p><img src="https://i.loli.net/2021/10/29/5RW6ONcBlPQ9gKC.png" alt="image.png"></p><h2 id="Honest"><a href="#Honest" class="headerlink" title="Honest"></a>Honest</h2><ul><li>$E[W_i]$ is a conservative estimator.</li></ul><p><img src="https://i.loli.net/2021/10/29/p1ytaHZzfnXLklj.png" alt="image.png"></p><ul><li>HIgher $D$ (higher connectivity) and lower $\pi$ (longer block interval) leads to lower fork rate and higher AT50.</li></ul><p><img src="https://i.loli.net/2021/10/29/5lFOjxJcCNeSqDt.png" alt="image.png"></p><h2 id="SM-1"><a href="#SM-1" class="headerlink" title="SM"></a>SM</h2><ul><li>$G_R(100,4)$ doesn’t reach 1. Depends on network model.</li><li>Why still fit? Because $\pi_i = \frac{\pi}{N}$ is ignorable.</li></ul><p><img src="https://i.loli.net/2021/10/29/KpklQeIrXsaOZV8.png" alt="image.png"></p><h1 id="Insights"><a href="#Insights" class="headerlink" title="Insights"></a>Insights</h1><ul><li><p>model honest revenue with fork rate.</p></li><li><p>computation of $\gamma$ using betweenness centrality to model a combinatorial problem.</p></li></ul>]]></content>
    
    
      
      
        
        
    <summary type="html">&lt;h1 id=&quot;Motivation&quot;&gt;&lt;a href=&quot;#Motivation&quot; class=&quot;headerlink&quot; title=&quot;Motivation&quot;&gt;&lt;/a&gt;Motivation&lt;/h1&gt;&lt;ul&gt;
&lt;li&gt;Honest-majority security</summary>
        
      
    
    
    
    <category term="Blockchain" scheme="https://www.virgilsun.com/categories/Blockchain/"/>
    
    
    <category term="Blockchain" scheme="https://www.virgilsun.com/tags/Blockchain/"/>
    
    <category term="Paper" scheme="https://www.virgilsun.com/tags/Paper/"/>
    
  </entry>
  
</feed>
